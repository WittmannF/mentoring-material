{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Solved - Embedding From Scratch on Keras.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxsZmAZ4Pc00",
        "colab_type": "text"
      },
      "source": [
        "# **Embeddings:** Live Example from Scratch\n",
        "In this notebook we will replicate the example provided in the powerpoint where embeddings were used to encode the neighborhoods of San Francisco. \n",
        "\n",
        "In order to be very ilustrative, we are going to use only one input - the neighborhood - with 4 different values: Tenderloin, Civic, Soma and F. District. As output we are going to have the hipothetical price of a house in each of those neighborhoods. \n",
        "\n",
        "### Imports\n",
        "Let's start with all the imports that we will need in this project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZdjl-dnPeeU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import numpy here\n",
        "import numpy as np\n",
        "\n",
        "# Import a Keras sequential model here\n",
        "from keras.models import Sequential\n",
        "\n",
        "# Import the following Keras Layers: Embedding, Flatten, Dense\n",
        "from keras.layers import Embedding, Flatten, Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_5aM8zXPeqn",
        "colab_type": "text"
      },
      "source": [
        "### Inputs and Outputs\n",
        "You are going to create both the input and output data! \n",
        "\n",
        "#### Input \n",
        "Please follow this rule:\n",
        "1. Create a random list with 12 values containing the neighborhoods of our example. Here's an example:\n",
        "```\n",
        "neigborhoods = ['Tenderloin',\n",
        "                'Civic',\n",
        "                'Tenderloin',\n",
        "                'Tenderloin',\n",
        "                'Soma',\n",
        "                ...\n",
        "                ]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bQe_qU6QFii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neigborhoods = ['Tenderloin',\n",
        "             'Civic',\n",
        "             'Tenderloin',\n",
        "             'Tenderloin',\n",
        "             'Soma',\n",
        "             'Soma',\n",
        "             'Soma',\n",
        "             'Civic',\n",
        "             'Civic',\n",
        "             'F. District',\n",
        "             'F. District',\n",
        "             'F. District'\n",
        "             ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdlLFsvWt1UV",
        "colab_type": "code",
        "outputId": "718810ee-3caa-4c88-a445-a864e008f51c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(neigborhoods)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOW07LfAT95x",
        "colab_type": "text"
      },
      "source": [
        "2. Declare a X variable with a numpy array where each neighborhood is encoded into one different integer. You can use either [LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) from sklearn or the following dictionary. \n",
        "> **OBS:** For compatibility with Keras, the input shape of X should be (12, 1)! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYN4i1-5QshX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx_to_neigh = {0: 'Tenderloin', 1: 'Soma', 2: 'Civic', 3: 'F. District'}\n",
        "neigh_to_idx = {'Tenderloin':0 , 'Soma':1 , 'Civic':2 , 'F. District':3}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m0T0D5DPnnH",
        "colab_type": "code",
        "outputId": "d8aea4b7-a2d5-479b-e4f2-44370febc10f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "X = np.array([neigh_to_idx[n] for n in neigborhoods]).reshape(12,1); X"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [2],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [2],\n",
              "       [2],\n",
              "       [3],\n",
              "       [3],\n",
              "       [3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIPaMC7SUuGE",
        "colab_type": "text"
      },
      "source": [
        "Done! Let's confirm that the input shape is (12, 1) as expected:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3S3LcJiT5Tq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert X.shape == (12,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNFJ4nxcP0e6",
        "colab_type": "text"
      },
      "source": [
        "### Output\n",
        "For the output, lets create random prices using the following rule:\n",
        "- If the neighborhood is either Tenderloin or Civic (cheap areas), assign a random price lower than 500 (the unit is kUSD). \n",
        "- If the neighborhood is either F. District or Soma (expensive areas), assign a random price higher than 500 (kUSD). \n",
        "\n",
        "> **OBS:** There's no need of creating an random algorithm. You can assign manually those prices! \n",
        "> **OBS2:** The shape of y should also be (12, 1)!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Key2WyoeP3RI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = np.array([[400],\n",
        "       [300],\n",
        "       [430],\n",
        "       [470],\n",
        "       [590],\n",
        "       [610],\n",
        "       [710],\n",
        "       [340],\n",
        "       [410],\n",
        "       [580],\n",
        "       [800],\n",
        "       [750]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eK16RvmhV4BB",
        "colab_type": "text"
      },
      "source": [
        "Let's confirm the output shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiL1rLx3V5nF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert y.shape == (12,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MB-9IxNAVUZs",
        "colab_type": "text"
      },
      "source": [
        "Let's now normalize the output for avoiding the selection of weird learning rates:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2URKMGWsRtFR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(y):\n",
        "    return (y-y.mean())/y.std()\n",
        "\n",
        "y = normalize(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdfSTnN5viMK",
        "colab_type": "code",
        "outputId": "fa900efb-5623-44ff-dc86-8d96f5337c41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.83796867],\n",
              "       [-1.47039785],\n",
              "       [-0.64823991],\n",
              "       [-0.39526824],\n",
              "       [ 0.36364678],\n",
              "       [ 0.49013262],\n",
              "       [ 1.1225618 ],\n",
              "       [-1.21742617],\n",
              "       [-0.77472575],\n",
              "       [ 0.30040386],\n",
              "       [ 1.69174806],\n",
              "       [ 1.37553347]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHKP_wf1Pn9e",
        "colab_type": "text"
      },
      "source": [
        "### Define Model\n",
        "Declare a Sequential Model with the following architecture:\n",
        "- One Embedding Layer: `Embedding(4, 2, input_length=1)`\n",
        "- One Flattening Operation: `Flatten`\n",
        "- One Dense layer with 1 neuron as output: `Dense(1)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLIEfhYH6-x4",
        "colab_type": "code",
        "outputId": "00e56288-b035-4f39-e37d-de68f0a8450e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "model = Sequential([Embedding(4, 2, input_length=1),\n",
        "                    Flatten(),\n",
        "                    Dense(1)\n",
        "                    \n",
        "])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQaDSV9Uw-4S",
        "colab_type": "code",
        "outputId": "3d8e1598-723a-4c5f-9280-fc2046d0519b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 1, 2)              8         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 3         \n",
            "=================================================================\n",
            "Total params: 11\n",
            "Trainable params: 11\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_I8NZMstWKVp",
        "colab_type": "text"
      },
      "source": [
        "### Compile Model\n",
        "Since this is a regression problem, make sure to select MSE as loss function. As optimizer, select Adam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fx69E1y8WNIv",
        "colab_type": "code",
        "outputId": "365ad8f3-57d3-4c3a-b814-a3dc55ad61df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "model.compile(optimizer='adam', loss='mse')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edi8vZEsWiuU",
        "colab_type": "text"
      },
      "source": [
        "### Fit Model\n",
        "Since this is a very light model, fit it for 1000 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzFp6H7-WkM9",
        "colab_type": "code",
        "outputId": "f4d25f17-1213-461c-9573-a044b40ed085",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X, y, epochs=1000, )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/1000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 0.9899\n",
            "Epoch 2/1000\n",
            "12/12 [==============================] - 0s 139us/step - loss: 0.9893\n",
            "Epoch 3/1000\n",
            "12/12 [==============================] - 0s 126us/step - loss: 0.9886\n",
            "Epoch 4/1000\n",
            "12/12 [==============================] - 0s 96us/step - loss: 0.9878\n",
            "Epoch 5/1000\n",
            "12/12 [==============================] - 0s 89us/step - loss: 0.9870\n",
            "Epoch 6/1000\n",
            "12/12 [==============================] - 0s 89us/step - loss: 0.9861\n",
            "Epoch 7/1000\n",
            "12/12 [==============================] - 0s 86us/step - loss: 0.9853\n",
            "Epoch 8/1000\n",
            "12/12 [==============================] - 0s 93us/step - loss: 0.9844\n",
            "Epoch 9/1000\n",
            "12/12 [==============================] - 0s 107us/step - loss: 0.9836\n",
            "Epoch 10/1000\n",
            "12/12 [==============================] - 0s 111us/step - loss: 0.9827\n",
            "Epoch 11/1000\n",
            "12/12 [==============================] - 0s 113us/step - loss: 0.9818\n",
            "Epoch 12/1000\n",
            "12/12 [==============================] - 0s 96us/step - loss: 0.9809\n",
            "Epoch 13/1000\n",
            "12/12 [==============================] - 0s 97us/step - loss: 0.9799\n",
            "Epoch 14/1000\n",
            "12/12 [==============================] - 0s 115us/step - loss: 0.9790\n",
            "Epoch 15/1000\n",
            "12/12 [==============================] - 0s 88us/step - loss: 0.9781\n",
            "Epoch 16/1000\n",
            "12/12 [==============================] - 0s 89us/step - loss: 0.9771\n",
            "Epoch 17/1000\n",
            "12/12 [==============================] - 0s 89us/step - loss: 0.9762\n",
            "Epoch 18/1000\n",
            "12/12 [==============================] - 0s 102us/step - loss: 0.9752\n",
            "Epoch 19/1000\n",
            "12/12 [==============================] - 0s 88us/step - loss: 0.9742\n",
            "Epoch 20/1000\n",
            "12/12 [==============================] - 0s 98us/step - loss: 0.9732\n",
            "Epoch 21/1000\n",
            "12/12 [==============================] - 0s 114us/step - loss: 0.9722\n",
            "Epoch 22/1000\n",
            "12/12 [==============================] - 0s 99us/step - loss: 0.9712\n",
            "Epoch 23/1000\n",
            "12/12 [==============================] - 0s 105us/step - loss: 0.9702\n",
            "Epoch 24/1000\n",
            "12/12 [==============================] - 0s 93us/step - loss: 0.9692\n",
            "Epoch 25/1000\n",
            "12/12 [==============================] - 0s 86us/step - loss: 0.9681\n",
            "Epoch 26/1000\n",
            "12/12 [==============================] - 0s 82us/step - loss: 0.9671\n",
            "Epoch 27/1000\n",
            "12/12 [==============================] - 0s 95us/step - loss: 0.9660\n",
            "Epoch 28/1000\n",
            "12/12 [==============================] - 0s 132us/step - loss: 0.9650\n",
            "Epoch 29/1000\n",
            "12/12 [==============================] - 0s 94us/step - loss: 0.9639\n",
            "Epoch 30/1000\n",
            "12/12 [==============================] - 0s 82us/step - loss: 0.9628\n",
            "Epoch 31/1000\n",
            "12/12 [==============================] - 0s 120us/step - loss: 0.9617\n",
            "Epoch 32/1000\n",
            "12/12 [==============================] - 0s 140us/step - loss: 0.9606\n",
            "Epoch 33/1000\n",
            "12/12 [==============================] - 0s 122us/step - loss: 0.9595\n",
            "Epoch 34/1000\n",
            "12/12 [==============================] - 0s 134us/step - loss: 0.9583\n",
            "Epoch 35/1000\n",
            "12/12 [==============================] - 0s 129us/step - loss: 0.9572\n",
            "Epoch 36/1000\n",
            "12/12 [==============================] - 0s 143us/step - loss: 0.9561\n",
            "Epoch 37/1000\n",
            "12/12 [==============================] - 0s 124us/step - loss: 0.9549\n",
            "Epoch 38/1000\n",
            "12/12 [==============================] - 0s 145us/step - loss: 0.9537\n",
            "Epoch 39/1000\n",
            "12/12 [==============================] - 0s 139us/step - loss: 0.9525\n",
            "Epoch 40/1000\n",
            "12/12 [==============================] - 0s 151us/step - loss: 0.9513\n",
            "Epoch 41/1000\n",
            "12/12 [==============================] - 0s 126us/step - loss: 0.9501\n",
            "Epoch 42/1000\n",
            "12/12 [==============================] - 0s 106us/step - loss: 0.9489\n",
            "Epoch 43/1000\n",
            "12/12 [==============================] - 0s 126us/step - loss: 0.9477\n",
            "Epoch 44/1000\n",
            "12/12 [==============================] - 0s 123us/step - loss: 0.9464\n",
            "Epoch 45/1000\n",
            "12/12 [==============================] - 0s 111us/step - loss: 0.9452\n",
            "Epoch 46/1000\n",
            "12/12 [==============================] - 0s 133us/step - loss: 0.9439\n",
            "Epoch 47/1000\n",
            "12/12 [==============================] - 0s 144us/step - loss: 0.9427\n",
            "Epoch 48/1000\n",
            "12/12 [==============================] - 0s 117us/step - loss: 0.9414\n",
            "Epoch 49/1000\n",
            "12/12 [==============================] - 0s 129us/step - loss: 0.9401\n",
            "Epoch 50/1000\n",
            "12/12 [==============================] - 0s 120us/step - loss: 0.9388\n",
            "Epoch 51/1000\n",
            "12/12 [==============================] - 0s 117us/step - loss: 0.9375\n",
            "Epoch 52/1000\n",
            "12/12 [==============================] - 0s 116us/step - loss: 0.9361\n",
            "Epoch 53/1000\n",
            "12/12 [==============================] - 0s 190us/step - loss: 0.9348\n",
            "Epoch 54/1000\n",
            "12/12 [==============================] - 0s 164us/step - loss: 0.9334\n",
            "Epoch 55/1000\n",
            "12/12 [==============================] - 0s 142us/step - loss: 0.9321\n",
            "Epoch 56/1000\n",
            "12/12 [==============================] - 0s 130us/step - loss: 0.9307\n",
            "Epoch 57/1000\n",
            "12/12 [==============================] - 0s 129us/step - loss: 0.9293\n",
            "Epoch 58/1000\n",
            "12/12 [==============================] - 0s 108us/step - loss: 0.9279\n",
            "Epoch 59/1000\n",
            "12/12 [==============================] - 0s 142us/step - loss: 0.9265\n",
            "Epoch 60/1000\n",
            "12/12 [==============================] - 0s 148us/step - loss: 0.9251\n",
            "Epoch 61/1000\n",
            "12/12 [==============================] - 0s 143us/step - loss: 0.9236\n",
            "Epoch 62/1000\n",
            "12/12 [==============================] - 0s 142us/step - loss: 0.9222\n",
            "Epoch 63/1000\n",
            "12/12 [==============================] - 0s 128us/step - loss: 0.9207\n",
            "Epoch 64/1000\n",
            "12/12 [==============================] - 0s 135us/step - loss: 0.9193\n",
            "Epoch 65/1000\n",
            "12/12 [==============================] - 0s 118us/step - loss: 0.9178\n",
            "Epoch 66/1000\n",
            "12/12 [==============================] - 0s 110us/step - loss: 0.9163\n",
            "Epoch 67/1000\n",
            "12/12 [==============================] - 0s 110us/step - loss: 0.9148\n",
            "Epoch 68/1000\n",
            "12/12 [==============================] - 0s 167us/step - loss: 0.9133\n",
            "Epoch 69/1000\n",
            "12/12 [==============================] - 0s 156us/step - loss: 0.9118\n",
            "Epoch 70/1000\n",
            "12/12 [==============================] - 0s 133us/step - loss: 0.9102\n",
            "Epoch 71/1000\n",
            "12/12 [==============================] - 0s 190us/step - loss: 0.9087\n",
            "Epoch 72/1000\n",
            "12/12 [==============================] - 0s 171us/step - loss: 0.9071\n",
            "Epoch 73/1000\n",
            "12/12 [==============================] - 0s 206us/step - loss: 0.9056\n",
            "Epoch 74/1000\n",
            "12/12 [==============================] - 0s 185us/step - loss: 0.9040\n",
            "Epoch 75/1000\n",
            "12/12 [==============================] - 0s 142us/step - loss: 0.9024\n",
            "Epoch 76/1000\n",
            "12/12 [==============================] - 0s 161us/step - loss: 0.9008\n",
            "Epoch 77/1000\n",
            "12/12 [==============================] - 0s 118us/step - loss: 0.8992\n",
            "Epoch 78/1000\n",
            "12/12 [==============================] - 0s 143us/step - loss: 0.8975\n",
            "Epoch 79/1000\n",
            "12/12 [==============================] - 0s 125us/step - loss: 0.8959\n",
            "Epoch 80/1000\n",
            "12/12 [==============================] - 0s 160us/step - loss: 0.8943\n",
            "Epoch 81/1000\n",
            "12/12 [==============================] - 0s 134us/step - loss: 0.8926\n",
            "Epoch 82/1000\n",
            "12/12 [==============================] - 0s 126us/step - loss: 0.8909\n",
            "Epoch 83/1000\n",
            "12/12 [==============================] - 0s 155us/step - loss: 0.8892\n",
            "Epoch 84/1000\n",
            "12/12 [==============================] - 0s 169us/step - loss: 0.8876\n",
            "Epoch 85/1000\n",
            "12/12 [==============================] - 0s 188us/step - loss: 0.8859\n",
            "Epoch 86/1000\n",
            "12/12 [==============================] - 0s 148us/step - loss: 0.8841\n",
            "Epoch 87/1000\n",
            "12/12 [==============================] - 0s 121us/step - loss: 0.8824\n",
            "Epoch 88/1000\n",
            "12/12 [==============================] - 0s 164us/step - loss: 0.8807\n",
            "Epoch 89/1000\n",
            "12/12 [==============================] - 0s 124us/step - loss: 0.8789\n",
            "Epoch 90/1000\n",
            "12/12 [==============================] - 0s 144us/step - loss: 0.8772\n",
            "Epoch 91/1000\n",
            "12/12 [==============================] - 0s 146us/step - loss: 0.8754\n",
            "Epoch 92/1000\n",
            "12/12 [==============================] - 0s 163us/step - loss: 0.8736\n",
            "Epoch 93/1000\n",
            "12/12 [==============================] - 0s 132us/step - loss: 0.8718\n",
            "Epoch 94/1000\n",
            "12/12 [==============================] - 0s 172us/step - loss: 0.8700\n",
            "Epoch 95/1000\n",
            "12/12 [==============================] - 0s 133us/step - loss: 0.8682\n",
            "Epoch 96/1000\n",
            "12/12 [==============================] - 0s 187us/step - loss: 0.8664\n",
            "Epoch 97/1000\n",
            "12/12 [==============================] - 0s 174us/step - loss: 0.8646\n",
            "Epoch 98/1000\n",
            "12/12 [==============================] - 0s 172us/step - loss: 0.8627\n",
            "Epoch 99/1000\n",
            "12/12 [==============================] - 0s 164us/step - loss: 0.8609\n",
            "Epoch 100/1000\n",
            "12/12 [==============================] - 0s 135us/step - loss: 0.8590\n",
            "Epoch 101/1000\n",
            "12/12 [==============================] - 0s 149us/step - loss: 0.8572\n",
            "Epoch 102/1000\n",
            "12/12 [==============================] - 0s 113us/step - loss: 0.8553\n",
            "Epoch 103/1000\n",
            "12/12 [==============================] - 0s 115us/step - loss: 0.8534\n",
            "Epoch 104/1000\n",
            "12/12 [==============================] - 0s 117us/step - loss: 0.8515\n",
            "Epoch 105/1000\n",
            "12/12 [==============================] - 0s 117us/step - loss: 0.8496\n",
            "Epoch 106/1000\n",
            "12/12 [==============================] - 0s 118us/step - loss: 0.8477\n",
            "Epoch 107/1000\n",
            "12/12 [==============================] - 0s 117us/step - loss: 0.8457\n",
            "Epoch 108/1000\n",
            "12/12 [==============================] - 0s 139us/step - loss: 0.8438\n",
            "Epoch 109/1000\n",
            "12/12 [==============================] - 0s 150us/step - loss: 0.8419\n",
            "Epoch 110/1000\n",
            "12/12 [==============================] - 0s 138us/step - loss: 0.8399\n",
            "Epoch 111/1000\n",
            "12/12 [==============================] - 0s 132us/step - loss: 0.8380\n",
            "Epoch 112/1000\n",
            "12/12 [==============================] - 0s 109us/step - loss: 0.8360\n",
            "Epoch 113/1000\n",
            "12/12 [==============================] - 0s 111us/step - loss: 0.8340\n",
            "Epoch 114/1000\n",
            "12/12 [==============================] - 0s 139us/step - loss: 0.8320\n",
            "Epoch 115/1000\n",
            "12/12 [==============================] - 0s 114us/step - loss: 0.8300\n",
            "Epoch 116/1000\n",
            "12/12 [==============================] - 0s 126us/step - loss: 0.8280\n",
            "Epoch 117/1000\n",
            "12/12 [==============================] - 0s 128us/step - loss: 0.8260\n",
            "Epoch 118/1000\n",
            "12/12 [==============================] - 0s 141us/step - loss: 0.8240\n",
            "Epoch 119/1000\n",
            "12/12 [==============================] - 0s 133us/step - loss: 0.8220\n",
            "Epoch 120/1000\n",
            "12/12 [==============================] - 0s 140us/step - loss: 0.8199\n",
            "Epoch 121/1000\n",
            "12/12 [==============================] - 0s 126us/step - loss: 0.8179\n",
            "Epoch 122/1000\n",
            "12/12 [==============================] - 0s 141us/step - loss: 0.8158\n",
            "Epoch 123/1000\n",
            "12/12 [==============================] - 0s 159us/step - loss: 0.8138\n",
            "Epoch 124/1000\n",
            "12/12 [==============================] - 0s 136us/step - loss: 0.8117\n",
            "Epoch 125/1000\n",
            "12/12 [==============================] - 0s 163us/step - loss: 0.8096\n",
            "Epoch 126/1000\n",
            "12/12 [==============================] - 0s 126us/step - loss: 0.8075\n",
            "Epoch 127/1000\n",
            "12/12 [==============================] - 0s 137us/step - loss: 0.8054\n",
            "Epoch 128/1000\n",
            "12/12 [==============================] - 0s 99us/step - loss: 0.8033\n",
            "Epoch 129/1000\n",
            "12/12 [==============================] - 0s 103us/step - loss: 0.8012\n",
            "Epoch 130/1000\n",
            "12/12 [==============================] - 0s 155us/step - loss: 0.7990\n",
            "Epoch 131/1000\n",
            "12/12 [==============================] - 0s 149us/step - loss: 0.7969\n",
            "Epoch 132/1000\n",
            "12/12 [==============================] - 0s 91us/step - loss: 0.7948\n",
            "Epoch 133/1000\n",
            "12/12 [==============================] - 0s 99us/step - loss: 0.7926\n",
            "Epoch 134/1000\n",
            "12/12 [==============================] - 0s 161us/step - loss: 0.7905\n",
            "Epoch 135/1000\n",
            "12/12 [==============================] - 0s 117us/step - loss: 0.7883\n",
            "Epoch 136/1000\n",
            "12/12 [==============================] - 0s 110us/step - loss: 0.7861\n",
            "Epoch 137/1000\n",
            "12/12 [==============================] - 0s 272us/step - loss: 0.7839\n",
            "Epoch 138/1000\n",
            "12/12 [==============================] - 0s 187us/step - loss: 0.7818\n",
            "Epoch 139/1000\n",
            "12/12 [==============================] - 0s 148us/step - loss: 0.7796\n",
            "Epoch 140/1000\n",
            "12/12 [==============================] - 0s 173us/step - loss: 0.7774\n",
            "Epoch 141/1000\n",
            "12/12 [==============================] - 0s 128us/step - loss: 0.7752\n",
            "Epoch 142/1000\n",
            "12/12 [==============================] - 0s 185us/step - loss: 0.7729\n",
            "Epoch 143/1000\n",
            "12/12 [==============================] - 0s 153us/step - loss: 0.7707\n",
            "Epoch 144/1000\n",
            "12/12 [==============================] - 0s 144us/step - loss: 0.7685\n",
            "Epoch 145/1000\n",
            "12/12 [==============================] - 0s 131us/step - loss: 0.7662\n",
            "Epoch 146/1000\n",
            "12/12 [==============================] - 0s 138us/step - loss: 0.7640\n",
            "Epoch 147/1000\n",
            "12/12 [==============================] - 0s 119us/step - loss: 0.7618\n",
            "Epoch 148/1000\n",
            "12/12 [==============================] - 0s 109us/step - loss: 0.7595\n",
            "Epoch 149/1000\n",
            "12/12 [==============================] - 0s 122us/step - loss: 0.7572\n",
            "Epoch 150/1000\n",
            "12/12 [==============================] - 0s 118us/step - loss: 0.7550\n",
            "Epoch 151/1000\n",
            "12/12 [==============================] - 0s 135us/step - loss: 0.7527\n",
            "Epoch 152/1000\n",
            "12/12 [==============================] - 0s 158us/step - loss: 0.7504\n",
            "Epoch 153/1000\n",
            "12/12 [==============================] - 0s 124us/step - loss: 0.7481\n",
            "Epoch 154/1000\n",
            "12/12 [==============================] - 0s 126us/step - loss: 0.7458\n",
            "Epoch 155/1000\n",
            "12/12 [==============================] - 0s 107us/step - loss: 0.7435\n",
            "Epoch 156/1000\n",
            "12/12 [==============================] - 0s 145us/step - loss: 0.7412\n",
            "Epoch 157/1000\n",
            "12/12 [==============================] - 0s 155us/step - loss: 0.7389\n",
            "Epoch 158/1000\n",
            "12/12 [==============================] - 0s 138us/step - loss: 0.7366\n",
            "Epoch 159/1000\n",
            "12/12 [==============================] - 0s 128us/step - loss: 0.7343\n",
            "Epoch 160/1000\n",
            "12/12 [==============================] - 0s 128us/step - loss: 0.7320\n",
            "Epoch 161/1000\n",
            "12/12 [==============================] - 0s 124us/step - loss: 0.7297\n",
            "Epoch 162/1000\n",
            "12/12 [==============================] - 0s 144us/step - loss: 0.7273\n",
            "Epoch 163/1000\n",
            "12/12 [==============================] - 0s 161us/step - loss: 0.7250\n",
            "Epoch 164/1000\n",
            "12/12 [==============================] - 0s 130us/step - loss: 0.7226\n",
            "Epoch 165/1000\n",
            "12/12 [==============================] - 0s 142us/step - loss: 0.7203\n",
            "Epoch 166/1000\n",
            "12/12 [==============================] - 0s 154us/step - loss: 0.7179\n",
            "Epoch 167/1000\n",
            "12/12 [==============================] - 0s 146us/step - loss: 0.7156\n",
            "Epoch 168/1000\n",
            "12/12 [==============================] - 0s 150us/step - loss: 0.7132\n",
            "Epoch 169/1000\n",
            "12/12 [==============================] - 0s 150us/step - loss: 0.7109\n",
            "Epoch 170/1000\n",
            "12/12 [==============================] - 0s 163us/step - loss: 0.7085\n",
            "Epoch 171/1000\n",
            "12/12 [==============================] - 0s 133us/step - loss: 0.7061\n",
            "Epoch 172/1000\n",
            "12/12 [==============================] - 0s 141us/step - loss: 0.7037\n",
            "Epoch 173/1000\n",
            "12/12 [==============================] - 0s 158us/step - loss: 0.7014\n",
            "Epoch 174/1000\n",
            "12/12 [==============================] - 0s 145us/step - loss: 0.6990\n",
            "Epoch 175/1000\n",
            "12/12 [==============================] - 0s 133us/step - loss: 0.6966\n",
            "Epoch 176/1000\n",
            "12/12 [==============================] - 0s 125us/step - loss: 0.6942\n",
            "Epoch 177/1000\n",
            "12/12 [==============================] - 0s 141us/step - loss: 0.6918\n",
            "Epoch 178/1000\n",
            "12/12 [==============================] - 0s 122us/step - loss: 0.6894\n",
            "Epoch 179/1000\n",
            "12/12 [==============================] - 0s 143us/step - loss: 0.6870\n",
            "Epoch 180/1000\n",
            "12/12 [==============================] - 0s 144us/step - loss: 0.6846\n",
            "Epoch 181/1000\n",
            "12/12 [==============================] - 0s 133us/step - loss: 0.6822\n",
            "Epoch 182/1000\n",
            "12/12 [==============================] - 0s 119us/step - loss: 0.6798\n",
            "Epoch 183/1000\n",
            "12/12 [==============================] - 0s 130us/step - loss: 0.6774\n",
            "Epoch 184/1000\n",
            "12/12 [==============================] - 0s 141us/step - loss: 0.6750\n",
            "Epoch 185/1000\n",
            "12/12 [==============================] - 0s 100us/step - loss: 0.6726\n",
            "Epoch 186/1000\n",
            "12/12 [==============================] - 0s 121us/step - loss: 0.6701\n",
            "Epoch 187/1000\n",
            "12/12 [==============================] - 0s 113us/step - loss: 0.6677\n",
            "Epoch 188/1000\n",
            "12/12 [==============================] - 0s 103us/step - loss: 0.6653\n",
            "Epoch 189/1000\n",
            "12/12 [==============================] - 0s 126us/step - loss: 0.6629\n",
            "Epoch 190/1000\n",
            "12/12 [==============================] - 0s 137us/step - loss: 0.6605\n",
            "Epoch 191/1000\n",
            "12/12 [==============================] - 0s 140us/step - loss: 0.6580\n",
            "Epoch 192/1000\n",
            "12/12 [==============================] - 0s 106us/step - loss: 0.6556\n",
            "Epoch 193/1000\n",
            "12/12 [==============================] - 0s 102us/step - loss: 0.6532\n",
            "Epoch 194/1000\n",
            "12/12 [==============================] - 0s 121us/step - loss: 0.6507\n",
            "Epoch 195/1000\n",
            "12/12 [==============================] - 0s 116us/step - loss: 0.6483\n",
            "Epoch 196/1000\n",
            "12/12 [==============================] - 0s 156us/step - loss: 0.6459\n",
            "Epoch 197/1000\n",
            "12/12 [==============================] - 0s 105us/step - loss: 0.6434\n",
            "Epoch 198/1000\n",
            "12/12 [==============================] - 0s 121us/step - loss: 0.6410\n",
            "Epoch 199/1000\n",
            "12/12 [==============================] - 0s 92us/step - loss: 0.6386\n",
            "Epoch 200/1000\n",
            "12/12 [==============================] - 0s 124us/step - loss: 0.6361\n",
            "Epoch 201/1000\n",
            "12/12 [==============================] - 0s 94us/step - loss: 0.6337\n",
            "Epoch 202/1000\n",
            "12/12 [==============================] - 0s 107us/step - loss: 0.6312\n",
            "Epoch 203/1000\n",
            "12/12 [==============================] - 0s 129us/step - loss: 0.6288\n",
            "Epoch 204/1000\n",
            "12/12 [==============================] - 0s 106us/step - loss: 0.6264\n",
            "Epoch 205/1000\n",
            "12/12 [==============================] - 0s 105us/step - loss: 0.6239\n",
            "Epoch 206/1000\n",
            "12/12 [==============================] - 0s 118us/step - loss: 0.6215\n",
            "Epoch 207/1000\n",
            "12/12 [==============================] - 0s 120us/step - loss: 0.6190\n",
            "Epoch 208/1000\n",
            "12/12 [==============================] - 0s 93us/step - loss: 0.6166\n",
            "Epoch 209/1000\n",
            "12/12 [==============================] - 0s 121us/step - loss: 0.6142\n",
            "Epoch 210/1000\n",
            "12/12 [==============================] - 0s 94us/step - loss: 0.6117\n",
            "Epoch 211/1000\n",
            "12/12 [==============================] - 0s 123us/step - loss: 0.6093\n",
            "Epoch 212/1000\n",
            "12/12 [==============================] - 0s 113us/step - loss: 0.6069\n",
            "Epoch 213/1000\n",
            "12/12 [==============================] - 0s 153us/step - loss: 0.6044\n",
            "Epoch 214/1000\n",
            "12/12 [==============================] - 0s 125us/step - loss: 0.6020\n",
            "Epoch 215/1000\n",
            "12/12 [==============================] - 0s 170us/step - loss: 0.5995\n",
            "Epoch 216/1000\n",
            "12/12 [==============================] - 0s 242us/step - loss: 0.5971\n",
            "Epoch 217/1000\n",
            "12/12 [==============================] - 0s 139us/step - loss: 0.5947\n",
            "Epoch 218/1000\n",
            "12/12 [==============================] - 0s 374us/step - loss: 0.5922\n",
            "Epoch 219/1000\n",
            "12/12 [==============================] - 0s 425us/step - loss: 0.5898\n",
            "Epoch 220/1000\n",
            "12/12 [==============================] - 0s 175us/step - loss: 0.5874\n",
            "Epoch 221/1000\n",
            "12/12 [==============================] - 0s 150us/step - loss: 0.5850\n",
            "Epoch 222/1000\n",
            "12/12 [==============================] - 0s 152us/step - loss: 0.5825\n",
            "Epoch 223/1000\n",
            "12/12 [==============================] - 0s 127us/step - loss: 0.5801\n",
            "Epoch 224/1000\n",
            "12/12 [==============================] - 0s 131us/step - loss: 0.5777\n",
            "Epoch 225/1000\n",
            "12/12 [==============================] - 0s 152us/step - loss: 0.5753\n",
            "Epoch 226/1000\n",
            "12/12 [==============================] - 0s 144us/step - loss: 0.5729\n",
            "Epoch 227/1000\n",
            "12/12 [==============================] - 0s 133us/step - loss: 0.5704\n",
            "Epoch 228/1000\n",
            "12/12 [==============================] - 0s 125us/step - loss: 0.5680\n",
            "Epoch 229/1000\n",
            "12/12 [==============================] - 0s 112us/step - loss: 0.5656\n",
            "Epoch 230/1000\n",
            "12/12 [==============================] - 0s 142us/step - loss: 0.5632\n",
            "Epoch 231/1000\n",
            "12/12 [==============================] - 0s 151us/step - loss: 0.5608\n",
            "Epoch 232/1000\n",
            "12/12 [==============================] - 0s 123us/step - loss: 0.5584\n",
            "Epoch 233/1000\n",
            "12/12 [==============================] - 0s 135us/step - loss: 0.5560\n",
            "Epoch 234/1000\n",
            "12/12 [==============================] - 0s 148us/step - loss: 0.5536\n",
            "Epoch 235/1000\n",
            "12/12 [==============================] - 0s 131us/step - loss: 0.5512\n",
            "Epoch 236/1000\n",
            "12/12 [==============================] - 0s 151us/step - loss: 0.5488\n",
            "Epoch 237/1000\n",
            "12/12 [==============================] - 0s 159us/step - loss: 0.5464\n",
            "Epoch 238/1000\n",
            "12/12 [==============================] - 0s 148us/step - loss: 0.5441\n",
            "Epoch 239/1000\n",
            "12/12 [==============================] - 0s 161us/step - loss: 0.5417\n",
            "Epoch 240/1000\n",
            "12/12 [==============================] - 0s 145us/step - loss: 0.5393\n",
            "Epoch 241/1000\n",
            "12/12 [==============================] - 0s 145us/step - loss: 0.5369\n",
            "Epoch 242/1000\n",
            "12/12 [==============================] - 0s 145us/step - loss: 0.5346\n",
            "Epoch 243/1000\n",
            "12/12 [==============================] - 0s 130us/step - loss: 0.5322\n",
            "Epoch 244/1000\n",
            "12/12 [==============================] - 0s 151us/step - loss: 0.5298\n",
            "Epoch 245/1000\n",
            "12/12 [==============================] - 0s 126us/step - loss: 0.5275\n",
            "Epoch 246/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.5251\n",
            "Epoch 247/1000\n",
            "12/12 [==============================] - 0s 183us/step - loss: 0.5228\n",
            "Epoch 248/1000\n",
            "12/12 [==============================] - 0s 169us/step - loss: 0.5205\n",
            "Epoch 249/1000\n",
            "12/12 [==============================] - 0s 142us/step - loss: 0.5181\n",
            "Epoch 250/1000\n",
            "12/12 [==============================] - 0s 129us/step - loss: 0.5158\n",
            "Epoch 251/1000\n",
            "12/12 [==============================] - 0s 124us/step - loss: 0.5135\n",
            "Epoch 252/1000\n",
            "12/12 [==============================] - 0s 135us/step - loss: 0.5111\n",
            "Epoch 253/1000\n",
            "12/12 [==============================] - 0s 104us/step - loss: 0.5088\n",
            "Epoch 254/1000\n",
            "12/12 [==============================] - 0s 161us/step - loss: 0.5065\n",
            "Epoch 255/1000\n",
            "12/12 [==============================] - 0s 101us/step - loss: 0.5042\n",
            "Epoch 256/1000\n",
            "12/12 [==============================] - 0s 123us/step - loss: 0.5019\n",
            "Epoch 257/1000\n",
            "12/12 [==============================] - 0s 135us/step - loss: 0.4996\n",
            "Epoch 258/1000\n",
            "12/12 [==============================] - 0s 150us/step - loss: 0.4973\n",
            "Epoch 259/1000\n",
            "12/12 [==============================] - 0s 137us/step - loss: 0.4950\n",
            "Epoch 260/1000\n",
            "12/12 [==============================] - 0s 138us/step - loss: 0.4927\n",
            "Epoch 261/1000\n",
            "12/12 [==============================] - 0s 143us/step - loss: 0.4904\n",
            "Epoch 262/1000\n",
            "12/12 [==============================] - 0s 122us/step - loss: 0.4882\n",
            "Epoch 263/1000\n",
            "12/12 [==============================] - 0s 128us/step - loss: 0.4859\n",
            "Epoch 264/1000\n",
            "12/12 [==============================] - 0s 109us/step - loss: 0.4836\n",
            "Epoch 265/1000\n",
            "12/12 [==============================] - 0s 139us/step - loss: 0.4814\n",
            "Epoch 266/1000\n",
            "12/12 [==============================] - 0s 158us/step - loss: 0.4791\n",
            "Epoch 267/1000\n",
            "12/12 [==============================] - 0s 212us/step - loss: 0.4769\n",
            "Epoch 268/1000\n",
            "12/12 [==============================] - 0s 107us/step - loss: 0.4747\n",
            "Epoch 269/1000\n",
            "12/12 [==============================] - 0s 87us/step - loss: 0.4724\n",
            "Epoch 270/1000\n",
            "12/12 [==============================] - 0s 215us/step - loss: 0.4702\n",
            "Epoch 271/1000\n",
            "12/12 [==============================] - 0s 202us/step - loss: 0.4680\n",
            "Epoch 272/1000\n",
            "12/12 [==============================] - 0s 224us/step - loss: 0.4658\n",
            "Epoch 273/1000\n",
            "12/12 [==============================] - 0s 208us/step - loss: 0.4636\n",
            "Epoch 274/1000\n",
            "12/12 [==============================] - 0s 240us/step - loss: 0.4614\n",
            "Epoch 275/1000\n",
            "12/12 [==============================] - 0s 250us/step - loss: 0.4592\n",
            "Epoch 276/1000\n",
            "12/12 [==============================] - 0s 211us/step - loss: 0.4570\n",
            "Epoch 277/1000\n",
            "12/12 [==============================] - 0s 174us/step - loss: 0.4548\n",
            "Epoch 278/1000\n",
            "12/12 [==============================] - 0s 156us/step - loss: 0.4527\n",
            "Epoch 279/1000\n",
            "12/12 [==============================] - 0s 154us/step - loss: 0.4505\n",
            "Epoch 280/1000\n",
            "12/12 [==============================] - 0s 165us/step - loss: 0.4483\n",
            "Epoch 281/1000\n",
            "12/12 [==============================] - 0s 147us/step - loss: 0.4462\n",
            "Epoch 282/1000\n",
            "12/12 [==============================] - 0s 179us/step - loss: 0.4441\n",
            "Epoch 283/1000\n",
            "12/12 [==============================] - 0s 145us/step - loss: 0.4419\n",
            "Epoch 284/1000\n",
            "12/12 [==============================] - 0s 149us/step - loss: 0.4398\n",
            "Epoch 285/1000\n",
            "12/12 [==============================] - 0s 128us/step - loss: 0.4377\n",
            "Epoch 286/1000\n",
            "12/12 [==============================] - 0s 157us/step - loss: 0.4356\n",
            "Epoch 287/1000\n",
            "12/12 [==============================] - 0s 170us/step - loss: 0.4335\n",
            "Epoch 288/1000\n",
            "12/12 [==============================] - 0s 128us/step - loss: 0.4314\n",
            "Epoch 289/1000\n",
            "12/12 [==============================] - 0s 131us/step - loss: 0.4293\n",
            "Epoch 290/1000\n",
            "12/12 [==============================] - 0s 136us/step - loss: 0.4272\n",
            "Epoch 291/1000\n",
            "12/12 [==============================] - 0s 150us/step - loss: 0.4251\n",
            "Epoch 292/1000\n",
            "12/12 [==============================] - 0s 162us/step - loss: 0.4231\n",
            "Epoch 293/1000\n",
            "12/12 [==============================] - 0s 149us/step - loss: 0.4210\n",
            "Epoch 294/1000\n",
            "12/12 [==============================] - 0s 155us/step - loss: 0.4189\n",
            "Epoch 295/1000\n",
            "12/12 [==============================] - 0s 176us/step - loss: 0.4169\n",
            "Epoch 296/1000\n",
            "12/12 [==============================] - 0s 138us/step - loss: 0.4149\n",
            "Epoch 297/1000\n",
            "12/12 [==============================] - 0s 179us/step - loss: 0.4128\n",
            "Epoch 298/1000\n",
            "12/12 [==============================] - 0s 171us/step - loss: 0.4108\n",
            "Epoch 299/1000\n",
            "12/12 [==============================] - 0s 152us/step - loss: 0.4088\n",
            "Epoch 300/1000\n",
            "12/12 [==============================] - 0s 131us/step - loss: 0.4068\n",
            "Epoch 301/1000\n",
            "12/12 [==============================] - 0s 188us/step - loss: 0.4048\n",
            "Epoch 302/1000\n",
            "12/12 [==============================] - 0s 215us/step - loss: 0.4028\n",
            "Epoch 303/1000\n",
            "12/12 [==============================] - 0s 192us/step - loss: 0.4009\n",
            "Epoch 304/1000\n",
            "12/12 [==============================] - 0s 142us/step - loss: 0.3989\n",
            "Epoch 305/1000\n",
            "12/12 [==============================] - 0s 180us/step - loss: 0.3969\n",
            "Epoch 306/1000\n",
            "12/12 [==============================] - 0s 134us/step - loss: 0.3950\n",
            "Epoch 307/1000\n",
            "12/12 [==============================] - 0s 153us/step - loss: 0.3930\n",
            "Epoch 308/1000\n",
            "12/12 [==============================] - 0s 133us/step - loss: 0.3911\n",
            "Epoch 309/1000\n",
            "12/12 [==============================] - 0s 118us/step - loss: 0.3892\n",
            "Epoch 310/1000\n",
            "12/12 [==============================] - 0s 123us/step - loss: 0.3873\n",
            "Epoch 311/1000\n",
            "12/12 [==============================] - 0s 182us/step - loss: 0.3854\n",
            "Epoch 312/1000\n",
            "12/12 [==============================] - 0s 129us/step - loss: 0.3835\n",
            "Epoch 313/1000\n",
            "12/12 [==============================] - 0s 123us/step - loss: 0.3816\n",
            "Epoch 314/1000\n",
            "12/12 [==============================] - 0s 152us/step - loss: 0.3797\n",
            "Epoch 315/1000\n",
            "12/12 [==============================] - 0s 146us/step - loss: 0.3778\n",
            "Epoch 316/1000\n",
            "12/12 [==============================] - 0s 120us/step - loss: 0.3760\n",
            "Epoch 317/1000\n",
            "12/12 [==============================] - 0s 136us/step - loss: 0.3741\n",
            "Epoch 318/1000\n",
            "12/12 [==============================] - 0s 137us/step - loss: 0.3723\n",
            "Epoch 319/1000\n",
            "12/12 [==============================] - 0s 128us/step - loss: 0.3704\n",
            "Epoch 320/1000\n",
            "12/12 [==============================] - 0s 119us/step - loss: 0.3686\n",
            "Epoch 321/1000\n",
            "12/12 [==============================] - 0s 210us/step - loss: 0.3668\n",
            "Epoch 322/1000\n",
            "12/12 [==============================] - 0s 143us/step - loss: 0.3650\n",
            "Epoch 323/1000\n",
            "12/12 [==============================] - 0s 153us/step - loss: 0.3632\n",
            "Epoch 324/1000\n",
            "12/12 [==============================] - 0s 150us/step - loss: 0.3614\n",
            "Epoch 325/1000\n",
            "12/12 [==============================] - 0s 147us/step - loss: 0.3596\n",
            "Epoch 326/1000\n",
            "12/12 [==============================] - 0s 174us/step - loss: 0.3578\n",
            "Epoch 327/1000\n",
            "12/12 [==============================] - 0s 135us/step - loss: 0.3561\n",
            "Epoch 328/1000\n",
            "12/12 [==============================] - 0s 157us/step - loss: 0.3543\n",
            "Epoch 329/1000\n",
            "12/12 [==============================] - 0s 126us/step - loss: 0.3526\n",
            "Epoch 330/1000\n",
            "12/12 [==============================] - 0s 148us/step - loss: 0.3509\n",
            "Epoch 331/1000\n",
            "12/12 [==============================] - 0s 165us/step - loss: 0.3491\n",
            "Epoch 332/1000\n",
            "12/12 [==============================] - 0s 137us/step - loss: 0.3474\n",
            "Epoch 333/1000\n",
            "12/12 [==============================] - 0s 134us/step - loss: 0.3457\n",
            "Epoch 334/1000\n",
            "12/12 [==============================] - 0s 145us/step - loss: 0.3440\n",
            "Epoch 335/1000\n",
            "12/12 [==============================] - 0s 114us/step - loss: 0.3423\n",
            "Epoch 336/1000\n",
            "12/12 [==============================] - 0s 105us/step - loss: 0.3407\n",
            "Epoch 337/1000\n",
            "12/12 [==============================] - 0s 109us/step - loss: 0.3390\n",
            "Epoch 338/1000\n",
            "12/12 [==============================] - 0s 110us/step - loss: 0.3373\n",
            "Epoch 339/1000\n",
            "12/12 [==============================] - 0s 117us/step - loss: 0.3357\n",
            "Epoch 340/1000\n",
            "12/12 [==============================] - 0s 122us/step - loss: 0.3340\n",
            "Epoch 341/1000\n",
            "12/12 [==============================] - 0s 102us/step - loss: 0.3324\n",
            "Epoch 342/1000\n",
            "12/12 [==============================] - 0s 144us/step - loss: 0.3308\n",
            "Epoch 343/1000\n",
            "12/12 [==============================] - 0s 142us/step - loss: 0.3292\n",
            "Epoch 344/1000\n",
            "12/12 [==============================] - 0s 177us/step - loss: 0.3276\n",
            "Epoch 345/1000\n",
            "12/12 [==============================] - 0s 156us/step - loss: 0.3260\n",
            "Epoch 346/1000\n",
            "12/12 [==============================] - 0s 258us/step - loss: 0.3244\n",
            "Epoch 347/1000\n",
            "12/12 [==============================] - 0s 192us/step - loss: 0.3228\n",
            "Epoch 348/1000\n",
            "12/12 [==============================] - 0s 192us/step - loss: 0.3213\n",
            "Epoch 349/1000\n",
            "12/12 [==============================] - 0s 154us/step - loss: 0.3197\n",
            "Epoch 350/1000\n",
            "12/12 [==============================] - 0s 148us/step - loss: 0.3182\n",
            "Epoch 351/1000\n",
            "12/12 [==============================] - 0s 150us/step - loss: 0.3166\n",
            "Epoch 352/1000\n",
            "12/12 [==============================] - 0s 207us/step - loss: 0.3151\n",
            "Epoch 353/1000\n",
            "12/12 [==============================] - 0s 225us/step - loss: 0.3136\n",
            "Epoch 354/1000\n",
            "12/12 [==============================] - 0s 152us/step - loss: 0.3121\n",
            "Epoch 355/1000\n",
            "12/12 [==============================] - 0s 168us/step - loss: 0.3106\n",
            "Epoch 356/1000\n",
            "12/12 [==============================] - 0s 201us/step - loss: 0.3091\n",
            "Epoch 357/1000\n",
            "12/12 [==============================] - 0s 174us/step - loss: 0.3076\n",
            "Epoch 358/1000\n",
            "12/12 [==============================] - 0s 129us/step - loss: 0.3062\n",
            "Epoch 359/1000\n",
            "12/12 [==============================] - 0s 144us/step - loss: 0.3047\n",
            "Epoch 360/1000\n",
            "12/12 [==============================] - 0s 113us/step - loss: 0.3033\n",
            "Epoch 361/1000\n",
            "12/12 [==============================] - 0s 124us/step - loss: 0.3018\n",
            "Epoch 362/1000\n",
            "12/12 [==============================] - 0s 147us/step - loss: 0.3004\n",
            "Epoch 363/1000\n",
            "12/12 [==============================] - 0s 168us/step - loss: 0.2990\n",
            "Epoch 364/1000\n",
            "12/12 [==============================] - 0s 152us/step - loss: 0.2976\n",
            "Epoch 365/1000\n",
            "12/12 [==============================] - 0s 143us/step - loss: 0.2962\n",
            "Epoch 366/1000\n",
            "12/12 [==============================] - 0s 135us/step - loss: 0.2948\n",
            "Epoch 367/1000\n",
            "12/12 [==============================] - 0s 136us/step - loss: 0.2934\n",
            "Epoch 368/1000\n",
            "12/12 [==============================] - 0s 165us/step - loss: 0.2920\n",
            "Epoch 369/1000\n",
            "12/12 [==============================] - 0s 137us/step - loss: 0.2907\n",
            "Epoch 370/1000\n",
            "12/12 [==============================] - 0s 151us/step - loss: 0.2893\n",
            "Epoch 371/1000\n",
            "12/12 [==============================] - 0s 152us/step - loss: 0.2880\n",
            "Epoch 372/1000\n",
            "12/12 [==============================] - 0s 130us/step - loss: 0.2866\n",
            "Epoch 373/1000\n",
            "12/12 [==============================] - 0s 138us/step - loss: 0.2853\n",
            "Epoch 374/1000\n",
            "12/12 [==============================] - 0s 145us/step - loss: 0.2840\n",
            "Epoch 375/1000\n",
            "12/12 [==============================] - 0s 150us/step - loss: 0.2827\n",
            "Epoch 376/1000\n",
            "12/12 [==============================] - 0s 131us/step - loss: 0.2814\n",
            "Epoch 377/1000\n",
            "12/12 [==============================] - 0s 137us/step - loss: 0.2801\n",
            "Epoch 378/1000\n",
            "12/12 [==============================] - 0s 131us/step - loss: 0.2788\n",
            "Epoch 379/1000\n",
            "12/12 [==============================] - 0s 137us/step - loss: 0.2775\n",
            "Epoch 380/1000\n",
            "12/12 [==============================] - 0s 128us/step - loss: 0.2763\n",
            "Epoch 381/1000\n",
            "12/12 [==============================] - 0s 142us/step - loss: 0.2750\n",
            "Epoch 382/1000\n",
            "12/12 [==============================] - 0s 134us/step - loss: 0.2738\n",
            "Epoch 383/1000\n",
            "12/12 [==============================] - 0s 175us/step - loss: 0.2726\n",
            "Epoch 384/1000\n",
            "12/12 [==============================] - 0s 173us/step - loss: 0.2713\n",
            "Epoch 385/1000\n",
            "12/12 [==============================] - 0s 173us/step - loss: 0.2701\n",
            "Epoch 386/1000\n",
            "12/12 [==============================] - 0s 162us/step - loss: 0.2689\n",
            "Epoch 387/1000\n",
            "12/12 [==============================] - 0s 163us/step - loss: 0.2677\n",
            "Epoch 388/1000\n",
            "12/12 [==============================] - 0s 171us/step - loss: 0.2665\n",
            "Epoch 389/1000\n",
            "12/12 [==============================] - 0s 150us/step - loss: 0.2653\n",
            "Epoch 390/1000\n",
            "12/12 [==============================] - 0s 166us/step - loss: 0.2642\n",
            "Epoch 391/1000\n",
            "12/12 [==============================] - 0s 161us/step - loss: 0.2630\n",
            "Epoch 392/1000\n",
            "12/12 [==============================] - 0s 131us/step - loss: 0.2619\n",
            "Epoch 393/1000\n",
            "12/12 [==============================] - 0s 149us/step - loss: 0.2607\n",
            "Epoch 394/1000\n",
            "12/12 [==============================] - 0s 154us/step - loss: 0.2596\n",
            "Epoch 395/1000\n",
            "12/12 [==============================] - 0s 130us/step - loss: 0.2585\n",
            "Epoch 396/1000\n",
            "12/12 [==============================] - 0s 161us/step - loss: 0.2573\n",
            "Epoch 397/1000\n",
            "12/12 [==============================] - 0s 130us/step - loss: 0.2562\n",
            "Epoch 398/1000\n",
            "12/12 [==============================] - 0s 167us/step - loss: 0.2551\n",
            "Epoch 399/1000\n",
            "12/12 [==============================] - 0s 153us/step - loss: 0.2540\n",
            "Epoch 400/1000\n",
            "12/12 [==============================] - 0s 180us/step - loss: 0.2529\n",
            "Epoch 401/1000\n",
            "12/12 [==============================] - 0s 209us/step - loss: 0.2519\n",
            "Epoch 402/1000\n",
            "12/12 [==============================] - 0s 170us/step - loss: 0.2508\n",
            "Epoch 403/1000\n",
            "12/12 [==============================] - 0s 159us/step - loss: 0.2497\n",
            "Epoch 404/1000\n",
            "12/12 [==============================] - 0s 182us/step - loss: 0.2487\n",
            "Epoch 405/1000\n",
            "12/12 [==============================] - 0s 178us/step - loss: 0.2477\n",
            "Epoch 406/1000\n",
            "12/12 [==============================] - 0s 146us/step - loss: 0.2466\n",
            "Epoch 407/1000\n",
            "12/12 [==============================] - 0s 193us/step - loss: 0.2456\n",
            "Epoch 408/1000\n",
            "12/12 [==============================] - 0s 182us/step - loss: 0.2446\n",
            "Epoch 409/1000\n",
            "12/12 [==============================] - 0s 148us/step - loss: 0.2436\n",
            "Epoch 410/1000\n",
            "12/12 [==============================] - 0s 147us/step - loss: 0.2426\n",
            "Epoch 411/1000\n",
            "12/12 [==============================] - 0s 133us/step - loss: 0.2416\n",
            "Epoch 412/1000\n",
            "12/12 [==============================] - 0s 155us/step - loss: 0.2406\n",
            "Epoch 413/1000\n",
            "12/12 [==============================] - 0s 169us/step - loss: 0.2396\n",
            "Epoch 414/1000\n",
            "12/12 [==============================] - 0s 184us/step - loss: 0.2387\n",
            "Epoch 415/1000\n",
            "12/12 [==============================] - 0s 134us/step - loss: 0.2377\n",
            "Epoch 416/1000\n",
            "12/12 [==============================] - 0s 108us/step - loss: 0.2367\n",
            "Epoch 417/1000\n",
            "12/12 [==============================] - 0s 115us/step - loss: 0.2358\n",
            "Epoch 418/1000\n",
            "12/12 [==============================] - 0s 111us/step - loss: 0.2349\n",
            "Epoch 419/1000\n",
            "12/12 [==============================] - 0s 126us/step - loss: 0.2339\n",
            "Epoch 420/1000\n",
            "12/12 [==============================] - 0s 145us/step - loss: 0.2330\n",
            "Epoch 421/1000\n",
            "12/12 [==============================] - 0s 117us/step - loss: 0.2321\n",
            "Epoch 422/1000\n",
            "12/12 [==============================] - 0s 483us/step - loss: 0.2312\n",
            "Epoch 423/1000\n",
            "12/12 [==============================] - 0s 110us/step - loss: 0.2303\n",
            "Epoch 424/1000\n",
            "12/12 [==============================] - 0s 151us/step - loss: 0.2294\n",
            "Epoch 425/1000\n",
            "12/12 [==============================] - 0s 128us/step - loss: 0.2285\n",
            "Epoch 426/1000\n",
            "12/12 [==============================] - 0s 143us/step - loss: 0.2277\n",
            "Epoch 427/1000\n",
            "12/12 [==============================] - 0s 109us/step - loss: 0.2268\n",
            "Epoch 428/1000\n",
            "12/12 [==============================] - 0s 120us/step - loss: 0.2259\n",
            "Epoch 429/1000\n",
            "12/12 [==============================] - 0s 222us/step - loss: 0.2251\n",
            "Epoch 430/1000\n",
            "12/12 [==============================] - 0s 169us/step - loss: 0.2242\n",
            "Epoch 431/1000\n",
            "12/12 [==============================] - 0s 158us/step - loss: 0.2234\n",
            "Epoch 432/1000\n",
            "12/12 [==============================] - 0s 123us/step - loss: 0.2226\n",
            "Epoch 433/1000\n",
            "12/12 [==============================] - 0s 109us/step - loss: 0.2218\n",
            "Epoch 434/1000\n",
            "12/12 [==============================] - 0s 130us/step - loss: 0.2209\n",
            "Epoch 435/1000\n",
            "12/12 [==============================] - 0s 119us/step - loss: 0.2201\n",
            "Epoch 436/1000\n",
            "12/12 [==============================] - 0s 162us/step - loss: 0.2193\n",
            "Epoch 437/1000\n",
            "12/12 [==============================] - 0s 187us/step - loss: 0.2185\n",
            "Epoch 438/1000\n",
            "12/12 [==============================] - 0s 156us/step - loss: 0.2178\n",
            "Epoch 439/1000\n",
            "12/12 [==============================] - 0s 150us/step - loss: 0.2170\n",
            "Epoch 440/1000\n",
            "12/12 [==============================] - 0s 176us/step - loss: 0.2162\n",
            "Epoch 441/1000\n",
            "12/12 [==============================] - 0s 161us/step - loss: 0.2154\n",
            "Epoch 442/1000\n",
            "12/12 [==============================] - 0s 122us/step - loss: 0.2147\n",
            "Epoch 443/1000\n",
            "12/12 [==============================] - 0s 143us/step - loss: 0.2139\n",
            "Epoch 444/1000\n",
            "12/12 [==============================] - 0s 116us/step - loss: 0.2132\n",
            "Epoch 445/1000\n",
            "12/12 [==============================] - 0s 130us/step - loss: 0.2124\n",
            "Epoch 446/1000\n",
            "12/12 [==============================] - 0s 143us/step - loss: 0.2117\n",
            "Epoch 447/1000\n",
            "12/12 [==============================] - 0s 154us/step - loss: 0.2110\n",
            "Epoch 448/1000\n",
            "12/12 [==============================] - 0s 128us/step - loss: 0.2103\n",
            "Epoch 449/1000\n",
            "12/12 [==============================] - 0s 136us/step - loss: 0.2095\n",
            "Epoch 450/1000\n",
            "12/12 [==============================] - 0s 172us/step - loss: 0.2088\n",
            "Epoch 451/1000\n",
            "12/12 [==============================] - 0s 170us/step - loss: 0.2081\n",
            "Epoch 452/1000\n",
            "12/12 [==============================] - 0s 164us/step - loss: 0.2075\n",
            "Epoch 453/1000\n",
            "12/12 [==============================] - 0s 124us/step - loss: 0.2068\n",
            "Epoch 454/1000\n",
            "12/12 [==============================] - 0s 117us/step - loss: 0.2061\n",
            "Epoch 455/1000\n",
            "12/12 [==============================] - 0s 137us/step - loss: 0.2054\n",
            "Epoch 456/1000\n",
            "12/12 [==============================] - 0s 126us/step - loss: 0.2047\n",
            "Epoch 457/1000\n",
            "12/12 [==============================] - 0s 128us/step - loss: 0.2041\n",
            "Epoch 458/1000\n",
            "12/12 [==============================] - 0s 130us/step - loss: 0.2034\n",
            "Epoch 459/1000\n",
            "12/12 [==============================] - 0s 151us/step - loss: 0.2028\n",
            "Epoch 460/1000\n",
            "12/12 [==============================] - 0s 159us/step - loss: 0.2021\n",
            "Epoch 461/1000\n",
            "12/12 [==============================] - 0s 157us/step - loss: 0.2015\n",
            "Epoch 462/1000\n",
            "12/12 [==============================] - 0s 129us/step - loss: 0.2009\n",
            "Epoch 463/1000\n",
            "12/12 [==============================] - 0s 182us/step - loss: 0.2002\n",
            "Epoch 464/1000\n",
            "12/12 [==============================] - 0s 132us/step - loss: 0.1996\n",
            "Epoch 465/1000\n",
            "12/12 [==============================] - 0s 143us/step - loss: 0.1990\n",
            "Epoch 466/1000\n",
            "12/12 [==============================] - 0s 136us/step - loss: 0.1984\n",
            "Epoch 467/1000\n",
            "12/12 [==============================] - 0s 135us/step - loss: 0.1978\n",
            "Epoch 468/1000\n",
            "12/12 [==============================] - 0s 150us/step - loss: 0.1972\n",
            "Epoch 469/1000\n",
            "12/12 [==============================] - 0s 146us/step - loss: 0.1966\n",
            "Epoch 470/1000\n",
            "12/12 [==============================] - 0s 164us/step - loss: 0.1960\n",
            "Epoch 471/1000\n",
            "12/12 [==============================] - 0s 118us/step - loss: 0.1954\n",
            "Epoch 472/1000\n",
            "12/12 [==============================] - 0s 126us/step - loss: 0.1949\n",
            "Epoch 473/1000\n",
            "12/12 [==============================] - 0s 150us/step - loss: 0.1943\n",
            "Epoch 474/1000\n",
            "12/12 [==============================] - 0s 153us/step - loss: 0.1937\n",
            "Epoch 475/1000\n",
            "12/12 [==============================] - 0s 124us/step - loss: 0.1932\n",
            "Epoch 476/1000\n",
            "12/12 [==============================] - 0s 130us/step - loss: 0.1926\n",
            "Epoch 477/1000\n",
            "12/12 [==============================] - 0s 157us/step - loss: 0.1921\n",
            "Epoch 478/1000\n",
            "12/12 [==============================] - 0s 149us/step - loss: 0.1915\n",
            "Epoch 479/1000\n",
            "12/12 [==============================] - 0s 164us/step - loss: 0.1910\n",
            "Epoch 480/1000\n",
            "12/12 [==============================] - 0s 164us/step - loss: 0.1905\n",
            "Epoch 481/1000\n",
            "12/12 [==============================] - 0s 129us/step - loss: 0.1900\n",
            "Epoch 482/1000\n",
            "12/12 [==============================] - 0s 123us/step - loss: 0.1894\n",
            "Epoch 483/1000\n",
            "12/12 [==============================] - 0s 150us/step - loss: 0.1889\n",
            "Epoch 484/1000\n",
            "12/12 [==============================] - 0s 165us/step - loss: 0.1884\n",
            "Epoch 485/1000\n",
            "12/12 [==============================] - 0s 139us/step - loss: 0.1879\n",
            "Epoch 486/1000\n",
            "12/12 [==============================] - 0s 132us/step - loss: 0.1874\n",
            "Epoch 487/1000\n",
            "12/12 [==============================] - 0s 114us/step - loss: 0.1869\n",
            "Epoch 488/1000\n",
            "12/12 [==============================] - 0s 183us/step - loss: 0.1864\n",
            "Epoch 489/1000\n",
            "12/12 [==============================] - 0s 127us/step - loss: 0.1859\n",
            "Epoch 490/1000\n",
            "12/12 [==============================] - 0s 135us/step - loss: 0.1855\n",
            "Epoch 491/1000\n",
            "12/12 [==============================] - 0s 111us/step - loss: 0.1850\n",
            "Epoch 492/1000\n",
            "12/12 [==============================] - 0s 140us/step - loss: 0.1845\n",
            "Epoch 493/1000\n",
            "12/12 [==============================] - 0s 149us/step - loss: 0.1840\n",
            "Epoch 494/1000\n",
            "12/12 [==============================] - 0s 127us/step - loss: 0.1836\n",
            "Epoch 495/1000\n",
            "12/12 [==============================] - 0s 139us/step - loss: 0.1831\n",
            "Epoch 496/1000\n",
            "12/12 [==============================] - 0s 106us/step - loss: 0.1827\n",
            "Epoch 497/1000\n",
            "12/12 [==============================] - 0s 116us/step - loss: 0.1822\n",
            "Epoch 498/1000\n",
            "12/12 [==============================] - 0s 130us/step - loss: 0.1818\n",
            "Epoch 499/1000\n",
            "12/12 [==============================] - 0s 145us/step - loss: 0.1813\n",
            "Epoch 500/1000\n",
            "12/12 [==============================] - 0s 150us/step - loss: 0.1809\n",
            "Epoch 501/1000\n",
            "12/12 [==============================] - 0s 120us/step - loss: 0.1805\n",
            "Epoch 502/1000\n",
            "12/12 [==============================] - 0s 129us/step - loss: 0.1800\n",
            "Epoch 503/1000\n",
            "12/12 [==============================] - 0s 141us/step - loss: 0.1796\n",
            "Epoch 504/1000\n",
            "12/12 [==============================] - 0s 170us/step - loss: 0.1792\n",
            "Epoch 505/1000\n",
            "12/12 [==============================] - 0s 141us/step - loss: 0.1788\n",
            "Epoch 506/1000\n",
            "12/12 [==============================] - 0s 154us/step - loss: 0.1784\n",
            "Epoch 507/1000\n",
            "12/12 [==============================] - 0s 120us/step - loss: 0.1780\n",
            "Epoch 508/1000\n",
            "12/12 [==============================] - 0s 133us/step - loss: 0.1776\n",
            "Epoch 509/1000\n",
            "12/12 [==============================] - 0s 137us/step - loss: 0.1772\n",
            "Epoch 510/1000\n",
            "12/12 [==============================] - 0s 170us/step - loss: 0.1768\n",
            "Epoch 511/1000\n",
            "12/12 [==============================] - 0s 117us/step - loss: 0.1764\n",
            "Epoch 512/1000\n",
            "12/12 [==============================] - 0s 123us/step - loss: 0.1760\n",
            "Epoch 513/1000\n",
            "12/12 [==============================] - 0s 176us/step - loss: 0.1756\n",
            "Epoch 514/1000\n",
            "12/12 [==============================] - 0s 128us/step - loss: 0.1753\n",
            "Epoch 515/1000\n",
            "12/12 [==============================] - 0s 157us/step - loss: 0.1749\n",
            "Epoch 516/1000\n",
            "12/12 [==============================] - 0s 157us/step - loss: 0.1745\n",
            "Epoch 517/1000\n",
            "12/12 [==============================] - 0s 124us/step - loss: 0.1742\n",
            "Epoch 518/1000\n",
            "12/12 [==============================] - 0s 134us/step - loss: 0.1738\n",
            "Epoch 519/1000\n",
            "12/12 [==============================] - 0s 139us/step - loss: 0.1734\n",
            "Epoch 520/1000\n",
            "12/12 [==============================] - 0s 122us/step - loss: 0.1731\n",
            "Epoch 521/1000\n",
            "12/12 [==============================] - 0s 163us/step - loss: 0.1727\n",
            "Epoch 522/1000\n",
            "12/12 [==============================] - 0s 130us/step - loss: 0.1724\n",
            "Epoch 523/1000\n",
            "12/12 [==============================] - 0s 135us/step - loss: 0.1721\n",
            "Epoch 524/1000\n",
            "12/12 [==============================] - 0s 127us/step - loss: 0.1717\n",
            "Epoch 525/1000\n",
            "12/12 [==============================] - 0s 140us/step - loss: 0.1714\n",
            "Epoch 526/1000\n",
            "12/12 [==============================] - 0s 149us/step - loss: 0.1711\n",
            "Epoch 527/1000\n",
            "12/12 [==============================] - 0s 150us/step - loss: 0.1707\n",
            "Epoch 528/1000\n",
            "12/12 [==============================] - 0s 169us/step - loss: 0.1704\n",
            "Epoch 529/1000\n",
            "12/12 [==============================] - 0s 160us/step - loss: 0.1701\n",
            "Epoch 530/1000\n",
            "12/12 [==============================] - 0s 127us/step - loss: 0.1698\n",
            "Epoch 531/1000\n",
            "12/12 [==============================] - 0s 157us/step - loss: 0.1695\n",
            "Epoch 532/1000\n",
            "12/12 [==============================] - 0s 139us/step - loss: 0.1691\n",
            "Epoch 533/1000\n",
            "12/12 [==============================] - 0s 138us/step - loss: 0.1688\n",
            "Epoch 534/1000\n",
            "12/12 [==============================] - 0s 138us/step - loss: 0.1685\n",
            "Epoch 535/1000\n",
            "12/12 [==============================] - 0s 167us/step - loss: 0.1682\n",
            "Epoch 536/1000\n",
            "12/12 [==============================] - 0s 105us/step - loss: 0.1679\n",
            "Epoch 537/1000\n",
            "12/12 [==============================] - 0s 136us/step - loss: 0.1676\n",
            "Epoch 538/1000\n",
            "12/12 [==============================] - 0s 112us/step - loss: 0.1674\n",
            "Epoch 539/1000\n",
            "12/12 [==============================] - 0s 144us/step - loss: 0.1671\n",
            "Epoch 540/1000\n",
            "12/12 [==============================] - 0s 90us/step - loss: 0.1668\n",
            "Epoch 541/1000\n",
            "12/12 [==============================] - 0s 110us/step - loss: 0.1665\n",
            "Epoch 542/1000\n",
            "12/12 [==============================] - 0s 104us/step - loss: 0.1662\n",
            "Epoch 543/1000\n",
            "12/12 [==============================] - 0s 206us/step - loss: 0.1660\n",
            "Epoch 544/1000\n",
            "12/12 [==============================] - 0s 319us/step - loss: 0.1657\n",
            "Epoch 545/1000\n",
            "12/12 [==============================] - 0s 126us/step - loss: 0.1654\n",
            "Epoch 546/1000\n",
            "12/12 [==============================] - 0s 136us/step - loss: 0.1651\n",
            "Epoch 547/1000\n",
            "12/12 [==============================] - 0s 802us/step - loss: 0.1649\n",
            "Epoch 548/1000\n",
            "12/12 [==============================] - 0s 301us/step - loss: 0.1646\n",
            "Epoch 549/1000\n",
            "12/12 [==============================] - 0s 180us/step - loss: 0.1644\n",
            "Epoch 550/1000\n",
            "12/12 [==============================] - 0s 191us/step - loss: 0.1641\n",
            "Epoch 551/1000\n",
            "12/12 [==============================] - 0s 160us/step - loss: 0.1639\n",
            "Epoch 552/1000\n",
            "12/12 [==============================] - 0s 153us/step - loss: 0.1636\n",
            "Epoch 553/1000\n",
            "12/12 [==============================] - 0s 174us/step - loss: 0.1634\n",
            "Epoch 554/1000\n",
            "12/12 [==============================] - 0s 133us/step - loss: 0.1631\n",
            "Epoch 555/1000\n",
            "12/12 [==============================] - 0s 162us/step - loss: 0.1629\n",
            "Epoch 556/1000\n",
            "12/12 [==============================] - 0s 118us/step - loss: 0.1627\n",
            "Epoch 557/1000\n",
            "12/12 [==============================] - 0s 181us/step - loss: 0.1624\n",
            "Epoch 558/1000\n",
            "12/12 [==============================] - 0s 232us/step - loss: 0.1622\n",
            "Epoch 559/1000\n",
            "12/12 [==============================] - 0s 221us/step - loss: 0.1620\n",
            "Epoch 560/1000\n",
            "12/12 [==============================] - 0s 154us/step - loss: 0.1617\n",
            "Epoch 561/1000\n",
            "12/12 [==============================] - 0s 300us/step - loss: 0.1615\n",
            "Epoch 562/1000\n",
            "12/12 [==============================] - 0s 246us/step - loss: 0.1613\n",
            "Epoch 563/1000\n",
            "12/12 [==============================] - 0s 197us/step - loss: 0.1611\n",
            "Epoch 564/1000\n",
            "12/12 [==============================] - 0s 151us/step - loss: 0.1609\n",
            "Epoch 565/1000\n",
            "12/12 [==============================] - 0s 286us/step - loss: 0.1606\n",
            "Epoch 566/1000\n",
            "12/12 [==============================] - 0s 201us/step - loss: 0.1604\n",
            "Epoch 567/1000\n",
            "12/12 [==============================] - 0s 202us/step - loss: 0.1602\n",
            "Epoch 568/1000\n",
            "12/12 [==============================] - 0s 180us/step - loss: 0.1600\n",
            "Epoch 569/1000\n",
            "12/12 [==============================] - 0s 132us/step - loss: 0.1598\n",
            "Epoch 570/1000\n",
            "12/12 [==============================] - 0s 156us/step - loss: 0.1596\n",
            "Epoch 571/1000\n",
            "12/12 [==============================] - 0s 135us/step - loss: 0.1594\n",
            "Epoch 572/1000\n",
            "12/12 [==============================] - 0s 168us/step - loss: 0.1592\n",
            "Epoch 573/1000\n",
            "12/12 [==============================] - 0s 162us/step - loss: 0.1590\n",
            "Epoch 574/1000\n",
            "12/12 [==============================] - 0s 155us/step - loss: 0.1588\n",
            "Epoch 575/1000\n",
            "12/12 [==============================] - 0s 140us/step - loss: 0.1586\n",
            "Epoch 576/1000\n",
            "12/12 [==============================] - 0s 169us/step - loss: 0.1584\n",
            "Epoch 577/1000\n",
            "12/12 [==============================] - 0s 135us/step - loss: 0.1583\n",
            "Epoch 578/1000\n",
            "12/12 [==============================] - 0s 135us/step - loss: 0.1581\n",
            "Epoch 579/1000\n",
            "12/12 [==============================] - 0s 146us/step - loss: 0.1579\n",
            "Epoch 580/1000\n",
            "12/12 [==============================] - 0s 151us/step - loss: 0.1577\n",
            "Epoch 581/1000\n",
            "12/12 [==============================] - 0s 166us/step - loss: 0.1575\n",
            "Epoch 582/1000\n",
            "12/12 [==============================] - 0s 191us/step - loss: 0.1574\n",
            "Epoch 583/1000\n",
            "12/12 [==============================] - 0s 180us/step - loss: 0.1572\n",
            "Epoch 584/1000\n",
            "12/12 [==============================] - 0s 174us/step - loss: 0.1570\n",
            "Epoch 585/1000\n",
            "12/12 [==============================] - 0s 183us/step - loss: 0.1569\n",
            "Epoch 586/1000\n",
            "12/12 [==============================] - 0s 177us/step - loss: 0.1567\n",
            "Epoch 587/1000\n",
            "12/12 [==============================] - 0s 141us/step - loss: 0.1565\n",
            "Epoch 588/1000\n",
            "12/12 [==============================] - 0s 176us/step - loss: 0.1564\n",
            "Epoch 589/1000\n",
            "12/12 [==============================] - 0s 180us/step - loss: 0.1562\n",
            "Epoch 590/1000\n",
            "12/12 [==============================] - 0s 177us/step - loss: 0.1561\n",
            "Epoch 591/1000\n",
            "12/12 [==============================] - 0s 179us/step - loss: 0.1559\n",
            "Epoch 592/1000\n",
            "12/12 [==============================] - 0s 138us/step - loss: 0.1557\n",
            "Epoch 593/1000\n",
            "12/12 [==============================] - 0s 136us/step - loss: 0.1556\n",
            "Epoch 594/1000\n",
            "12/12 [==============================] - 0s 167us/step - loss: 0.1554\n",
            "Epoch 595/1000\n",
            "12/12 [==============================] - 0s 183us/step - loss: 0.1553\n",
            "Epoch 596/1000\n",
            "12/12 [==============================] - 0s 172us/step - loss: 0.1551\n",
            "Epoch 597/1000\n",
            "12/12 [==============================] - 0s 170us/step - loss: 0.1550\n",
            "Epoch 598/1000\n",
            "12/12 [==============================] - 0s 162us/step - loss: 0.1549\n",
            "Epoch 599/1000\n",
            "12/12 [==============================] - 0s 161us/step - loss: 0.1547\n",
            "Epoch 600/1000\n",
            "12/12 [==============================] - 0s 120us/step - loss: 0.1546\n",
            "Epoch 601/1000\n",
            "12/12 [==============================] - 0s 166us/step - loss: 0.1544\n",
            "Epoch 602/1000\n",
            "12/12 [==============================] - 0s 169us/step - loss: 0.1543\n",
            "Epoch 603/1000\n",
            "12/12 [==============================] - 0s 186us/step - loss: 0.1542\n",
            "Epoch 604/1000\n",
            "12/12 [==============================] - 0s 167us/step - loss: 0.1540\n",
            "Epoch 605/1000\n",
            "12/12 [==============================] - 0s 166us/step - loss: 0.1539\n",
            "Epoch 606/1000\n",
            "12/12 [==============================] - 0s 204us/step - loss: 0.1538\n",
            "Epoch 607/1000\n",
            "12/12 [==============================] - 0s 137us/step - loss: 0.1536\n",
            "Epoch 608/1000\n",
            "12/12 [==============================] - 0s 188us/step - loss: 0.1535\n",
            "Epoch 609/1000\n",
            "12/12 [==============================] - 0s 170us/step - loss: 0.1534\n",
            "Epoch 610/1000\n",
            "12/12 [==============================] - 0s 159us/step - loss: 0.1533\n",
            "Epoch 611/1000\n",
            "12/12 [==============================] - 0s 147us/step - loss: 0.1532\n",
            "Epoch 612/1000\n",
            "12/12 [==============================] - 0s 209us/step - loss: 0.1530\n",
            "Epoch 613/1000\n",
            "12/12 [==============================] - 0s 155us/step - loss: 0.1529\n",
            "Epoch 614/1000\n",
            "12/12 [==============================] - 0s 134us/step - loss: 0.1528\n",
            "Epoch 615/1000\n",
            "12/12 [==============================] - 0s 135us/step - loss: 0.1527\n",
            "Epoch 616/1000\n",
            "12/12 [==============================] - 0s 132us/step - loss: 0.1526\n",
            "Epoch 617/1000\n",
            "12/12 [==============================] - 0s 141us/step - loss: 0.1525\n",
            "Epoch 618/1000\n",
            "12/12 [==============================] - 0s 134us/step - loss: 0.1524\n",
            "Epoch 619/1000\n",
            "12/12 [==============================] - 0s 133us/step - loss: 0.1522\n",
            "Epoch 620/1000\n",
            "12/12 [==============================] - 0s 158us/step - loss: 0.1521\n",
            "Epoch 621/1000\n",
            "12/12 [==============================] - 0s 131us/step - loss: 0.1520\n",
            "Epoch 622/1000\n",
            "12/12 [==============================] - 0s 133us/step - loss: 0.1519\n",
            "Epoch 623/1000\n",
            "12/12 [==============================] - 0s 135us/step - loss: 0.1518\n",
            "Epoch 624/1000\n",
            "12/12 [==============================] - 0s 125us/step - loss: 0.1517\n",
            "Epoch 625/1000\n",
            "12/12 [==============================] - 0s 127us/step - loss: 0.1516\n",
            "Epoch 626/1000\n",
            "12/12 [==============================] - 0s 166us/step - loss: 0.1515\n",
            "Epoch 627/1000\n",
            "12/12 [==============================] - 0s 156us/step - loss: 0.1514\n",
            "Epoch 628/1000\n",
            "12/12 [==============================] - 0s 137us/step - loss: 0.1513\n",
            "Epoch 629/1000\n",
            "12/12 [==============================] - 0s 163us/step - loss: 0.1512\n",
            "Epoch 630/1000\n",
            "12/12 [==============================] - 0s 148us/step - loss: 0.1511\n",
            "Epoch 631/1000\n",
            "12/12 [==============================] - 0s 183us/step - loss: 0.1510\n",
            "Epoch 632/1000\n",
            "12/12 [==============================] - 0s 156us/step - loss: 0.1510\n",
            "Epoch 633/1000\n",
            "12/12 [==============================] - 0s 164us/step - loss: 0.1509\n",
            "Epoch 634/1000\n",
            "12/12 [==============================] - 0s 137us/step - loss: 0.1508\n",
            "Epoch 635/1000\n",
            "12/12 [==============================] - 0s 145us/step - loss: 0.1507\n",
            "Epoch 636/1000\n",
            "12/12 [==============================] - 0s 137us/step - loss: 0.1506\n",
            "Epoch 637/1000\n",
            "12/12 [==============================] - 0s 137us/step - loss: 0.1505\n",
            "Epoch 638/1000\n",
            "12/12 [==============================] - 0s 187us/step - loss: 0.1504\n",
            "Epoch 639/1000\n",
            "12/12 [==============================] - 0s 168us/step - loss: 0.1503\n",
            "Epoch 640/1000\n",
            "12/12 [==============================] - 0s 152us/step - loss: 0.1503\n",
            "Epoch 641/1000\n",
            "12/12 [==============================] - 0s 156us/step - loss: 0.1502\n",
            "Epoch 642/1000\n",
            "12/12 [==============================] - 0s 162us/step - loss: 0.1501\n",
            "Epoch 643/1000\n",
            "12/12 [==============================] - 0s 146us/step - loss: 0.1500\n",
            "Epoch 644/1000\n",
            "12/12 [==============================] - 0s 168us/step - loss: 0.1499\n",
            "Epoch 645/1000\n",
            "12/12 [==============================] - 0s 165us/step - loss: 0.1499\n",
            "Epoch 646/1000\n",
            "12/12 [==============================] - 0s 152us/step - loss: 0.1498\n",
            "Epoch 647/1000\n",
            "12/12 [==============================] - 0s 158us/step - loss: 0.1497\n",
            "Epoch 648/1000\n",
            "12/12 [==============================] - 0s 150us/step - loss: 0.1497\n",
            "Epoch 649/1000\n",
            "12/12 [==============================] - 0s 166us/step - loss: 0.1496\n",
            "Epoch 650/1000\n",
            "12/12 [==============================] - 0s 191us/step - loss: 0.1495\n",
            "Epoch 651/1000\n",
            "12/12 [==============================] - 0s 157us/step - loss: 0.1494\n",
            "Epoch 652/1000\n",
            "12/12 [==============================] - 0s 157us/step - loss: 0.1494\n",
            "Epoch 653/1000\n",
            "12/12 [==============================] - 0s 161us/step - loss: 0.1493\n",
            "Epoch 654/1000\n",
            "12/12 [==============================] - 0s 142us/step - loss: 0.1492\n",
            "Epoch 655/1000\n",
            "12/12 [==============================] - 0s 155us/step - loss: 0.1492\n",
            "Epoch 656/1000\n",
            "12/12 [==============================] - 0s 160us/step - loss: 0.1491\n",
            "Epoch 657/1000\n",
            "12/12 [==============================] - 0s 132us/step - loss: 0.1490\n",
            "Epoch 658/1000\n",
            "12/12 [==============================] - 0s 132us/step - loss: 0.1490\n",
            "Epoch 659/1000\n",
            "12/12 [==============================] - 0s 149us/step - loss: 0.1489\n",
            "Epoch 660/1000\n",
            "12/12 [==============================] - 0s 145us/step - loss: 0.1488\n",
            "Epoch 661/1000\n",
            "12/12 [==============================] - 0s 180us/step - loss: 0.1488\n",
            "Epoch 662/1000\n",
            "12/12 [==============================] - 0s 178us/step - loss: 0.1487\n",
            "Epoch 663/1000\n",
            "12/12 [==============================] - 0s 138us/step - loss: 0.1487\n",
            "Epoch 664/1000\n",
            "12/12 [==============================] - 0s 168us/step - loss: 0.1486\n",
            "Epoch 665/1000\n",
            "12/12 [==============================] - 0s 160us/step - loss: 0.1486\n",
            "Epoch 666/1000\n",
            "12/12 [==============================] - 0s 151us/step - loss: 0.1485\n",
            "Epoch 667/1000\n",
            "12/12 [==============================] - 0s 133us/step - loss: 0.1484\n",
            "Epoch 668/1000\n",
            "12/12 [==============================] - 0s 139us/step - loss: 0.1484\n",
            "Epoch 669/1000\n",
            "12/12 [==============================] - 0s 166us/step - loss: 0.1483\n",
            "Epoch 670/1000\n",
            "12/12 [==============================] - 0s 180us/step - loss: 0.1483\n",
            "Epoch 671/1000\n",
            "12/12 [==============================] - 0s 143us/step - loss: 0.1482\n",
            "Epoch 672/1000\n",
            "12/12 [==============================] - 0s 177us/step - loss: 0.1482\n",
            "Epoch 673/1000\n",
            "12/12 [==============================] - 0s 132us/step - loss: 0.1481\n",
            "Epoch 674/1000\n",
            "12/12 [==============================] - 0s 162us/step - loss: 0.1481\n",
            "Epoch 675/1000\n",
            "12/12 [==============================] - 0s 118us/step - loss: 0.1480\n",
            "Epoch 676/1000\n",
            "12/12 [==============================] - 0s 146us/step - loss: 0.1480\n",
            "Epoch 677/1000\n",
            "12/12 [==============================] - 0s 116us/step - loss: 0.1479\n",
            "Epoch 678/1000\n",
            "12/12 [==============================] - 0s 136us/step - loss: 0.1479\n",
            "Epoch 679/1000\n",
            "12/12 [==============================] - 0s 173us/step - loss: 0.1478\n",
            "Epoch 680/1000\n",
            "12/12 [==============================] - 0s 100us/step - loss: 0.1478\n",
            "Epoch 681/1000\n",
            "12/12 [==============================] - 0s 118us/step - loss: 0.1477\n",
            "Epoch 682/1000\n",
            "12/12 [==============================] - 0s 167us/step - loss: 0.1477\n",
            "Epoch 683/1000\n",
            "12/12 [==============================] - 0s 88us/step - loss: 0.1477\n",
            "Epoch 684/1000\n",
            "12/12 [==============================] - 0s 90us/step - loss: 0.1476\n",
            "Epoch 685/1000\n",
            "12/12 [==============================] - 0s 243us/step - loss: 0.1476\n",
            "Epoch 686/1000\n",
            "12/12 [==============================] - 0s 100us/step - loss: 0.1475\n",
            "Epoch 687/1000\n",
            "12/12 [==============================] - 0s 131us/step - loss: 0.1475\n",
            "Epoch 688/1000\n",
            "12/12 [==============================] - 0s 130us/step - loss: 0.1474\n",
            "Epoch 689/1000\n",
            "12/12 [==============================] - 0s 91us/step - loss: 0.1474\n",
            "Epoch 690/1000\n",
            "12/12 [==============================] - 0s 116us/step - loss: 0.1474\n",
            "Epoch 691/1000\n",
            "12/12 [==============================] - 0s 131us/step - loss: 0.1473\n",
            "Epoch 692/1000\n",
            "12/12 [==============================] - 0s 92us/step - loss: 0.1473\n",
            "Epoch 693/1000\n",
            "12/12 [==============================] - 0s 166us/step - loss: 0.1473\n",
            "Epoch 694/1000\n",
            "12/12 [==============================] - 0s 108us/step - loss: 0.1472\n",
            "Epoch 695/1000\n",
            "12/12 [==============================] - 0s 105us/step - loss: 0.1472\n",
            "Epoch 696/1000\n",
            "12/12 [==============================] - 0s 107us/step - loss: 0.1471\n",
            "Epoch 697/1000\n",
            "12/12 [==============================] - 0s 123us/step - loss: 0.1471\n",
            "Epoch 698/1000\n",
            "12/12 [==============================] - 0s 195us/step - loss: 0.1471\n",
            "Epoch 699/1000\n",
            "12/12 [==============================] - 0s 97us/step - loss: 0.1470\n",
            "Epoch 700/1000\n",
            "12/12 [==============================] - 0s 160us/step - loss: 0.1470\n",
            "Epoch 701/1000\n",
            "12/12 [==============================] - 0s 107us/step - loss: 0.1470\n",
            "Epoch 702/1000\n",
            "12/12 [==============================] - 0s 106us/step - loss: 0.1469\n",
            "Epoch 703/1000\n",
            "12/12 [==============================] - 0s 102us/step - loss: 0.1469\n",
            "Epoch 704/1000\n",
            "12/12 [==============================] - 0s 123us/step - loss: 0.1469\n",
            "Epoch 705/1000\n",
            "12/12 [==============================] - 0s 168us/step - loss: 0.1469\n",
            "Epoch 706/1000\n",
            "12/12 [==============================] - 0s 143us/step - loss: 0.1468\n",
            "Epoch 707/1000\n",
            "12/12 [==============================] - 0s 148us/step - loss: 0.1468\n",
            "Epoch 708/1000\n",
            "12/12 [==============================] - 0s 144us/step - loss: 0.1468\n",
            "Epoch 709/1000\n",
            "12/12 [==============================] - 0s 134us/step - loss: 0.1467\n",
            "Epoch 710/1000\n",
            "12/12 [==============================] - 0s 165us/step - loss: 0.1467\n",
            "Epoch 711/1000\n",
            "12/12 [==============================] - 0s 191us/step - loss: 0.1467\n",
            "Epoch 712/1000\n",
            "12/12 [==============================] - 0s 147us/step - loss: 0.1466\n",
            "Epoch 713/1000\n",
            "12/12 [==============================] - 0s 175us/step - loss: 0.1466\n",
            "Epoch 714/1000\n",
            "12/12 [==============================] - 0s 153us/step - loss: 0.1466\n",
            "Epoch 715/1000\n",
            "12/12 [==============================] - 0s 159us/step - loss: 0.1466\n",
            "Epoch 716/1000\n",
            "12/12 [==============================] - 0s 164us/step - loss: 0.1465\n",
            "Epoch 717/1000\n",
            "12/12 [==============================] - 0s 167us/step - loss: 0.1465\n",
            "Epoch 718/1000\n",
            "12/12 [==============================] - 0s 158us/step - loss: 0.1465\n",
            "Epoch 719/1000\n",
            "12/12 [==============================] - 0s 144us/step - loss: 0.1465\n",
            "Epoch 720/1000\n",
            "12/12 [==============================] - 0s 145us/step - loss: 0.1464\n",
            "Epoch 721/1000\n",
            "12/12 [==============================] - 0s 187us/step - loss: 0.1464\n",
            "Epoch 722/1000\n",
            "12/12 [==============================] - 0s 175us/step - loss: 0.1464\n",
            "Epoch 723/1000\n",
            "12/12 [==============================] - 0s 133us/step - loss: 0.1464\n",
            "Epoch 724/1000\n",
            "12/12 [==============================] - 0s 128us/step - loss: 0.1463\n",
            "Epoch 725/1000\n",
            "12/12 [==============================] - 0s 143us/step - loss: 0.1463\n",
            "Epoch 726/1000\n",
            "12/12 [==============================] - 0s 191us/step - loss: 0.1463\n",
            "Epoch 727/1000\n",
            "12/12 [==============================] - 0s 184us/step - loss: 0.1463\n",
            "Epoch 728/1000\n",
            "12/12 [==============================] - 0s 184us/step - loss: 0.1463\n",
            "Epoch 729/1000\n",
            "12/12 [==============================] - 0s 155us/step - loss: 0.1462\n",
            "Epoch 730/1000\n",
            "12/12 [==============================] - 0s 157us/step - loss: 0.1462\n",
            "Epoch 731/1000\n",
            "12/12 [==============================] - 0s 151us/step - loss: 0.1462\n",
            "Epoch 732/1000\n",
            "12/12 [==============================] - 0s 165us/step - loss: 0.1462\n",
            "Epoch 733/1000\n",
            "12/12 [==============================] - 0s 141us/step - loss: 0.1462\n",
            "Epoch 734/1000\n",
            "12/12 [==============================] - 0s 129us/step - loss: 0.1461\n",
            "Epoch 735/1000\n",
            "12/12 [==============================] - 0s 132us/step - loss: 0.1461\n",
            "Epoch 736/1000\n",
            "12/12 [==============================] - 0s 162us/step - loss: 0.1461\n",
            "Epoch 737/1000\n",
            "12/12 [==============================] - 0s 161us/step - loss: 0.1461\n",
            "Epoch 738/1000\n",
            "12/12 [==============================] - 0s 157us/step - loss: 0.1461\n",
            "Epoch 739/1000\n",
            "12/12 [==============================] - 0s 185us/step - loss: 0.1460\n",
            "Epoch 740/1000\n",
            "12/12 [==============================] - 0s 114us/step - loss: 0.1460\n",
            "Epoch 741/1000\n",
            "12/12 [==============================] - 0s 141us/step - loss: 0.1460\n",
            "Epoch 742/1000\n",
            "12/12 [==============================] - 0s 106us/step - loss: 0.1460\n",
            "Epoch 743/1000\n",
            "12/12 [==============================] - 0s 142us/step - loss: 0.1460\n",
            "Epoch 744/1000\n",
            "12/12 [==============================] - 0s 119us/step - loss: 0.1460\n",
            "Epoch 745/1000\n",
            "12/12 [==============================] - 0s 117us/step - loss: 0.1459\n",
            "Epoch 746/1000\n",
            "12/12 [==============================] - 0s 100us/step - loss: 0.1459\n",
            "Epoch 747/1000\n",
            "12/12 [==============================] - 0s 119us/step - loss: 0.1459\n",
            "Epoch 748/1000\n",
            "12/12 [==============================] - 0s 178us/step - loss: 0.1459\n",
            "Epoch 749/1000\n",
            "12/12 [==============================] - 0s 156us/step - loss: 0.1459\n",
            "Epoch 750/1000\n",
            "12/12 [==============================] - 0s 175us/step - loss: 0.1459\n",
            "Epoch 751/1000\n",
            "12/12 [==============================] - 0s 150us/step - loss: 0.1459\n",
            "Epoch 752/1000\n",
            "12/12 [==============================] - 0s 189us/step - loss: 0.1458\n",
            "Epoch 753/1000\n",
            "12/12 [==============================] - 0s 140us/step - loss: 0.1458\n",
            "Epoch 754/1000\n",
            "12/12 [==============================] - 0s 173us/step - loss: 0.1458\n",
            "Epoch 755/1000\n",
            "12/12 [==============================] - 0s 151us/step - loss: 0.1458\n",
            "Epoch 756/1000\n",
            "12/12 [==============================] - 0s 134us/step - loss: 0.1458\n",
            "Epoch 757/1000\n",
            "12/12 [==============================] - 0s 132us/step - loss: 0.1458\n",
            "Epoch 758/1000\n",
            "12/12 [==============================] - 0s 131us/step - loss: 0.1458\n",
            "Epoch 759/1000\n",
            "12/12 [==============================] - 0s 134us/step - loss: 0.1458\n",
            "Epoch 760/1000\n",
            "12/12 [==============================] - 0s 119us/step - loss: 0.1457\n",
            "Epoch 761/1000\n",
            "12/12 [==============================] - 0s 157us/step - loss: 0.1457\n",
            "Epoch 762/1000\n",
            "12/12 [==============================] - 0s 184us/step - loss: 0.1457\n",
            "Epoch 763/1000\n",
            "12/12 [==============================] - 0s 166us/step - loss: 0.1457\n",
            "Epoch 764/1000\n",
            "12/12 [==============================] - 0s 170us/step - loss: 0.1457\n",
            "Epoch 765/1000\n",
            "12/12 [==============================] - 0s 156us/step - loss: 0.1457\n",
            "Epoch 766/1000\n",
            "12/12 [==============================] - 0s 171us/step - loss: 0.1457\n",
            "Epoch 767/1000\n",
            "12/12 [==============================] - 0s 180us/step - loss: 0.1457\n",
            "Epoch 768/1000\n",
            "12/12 [==============================] - 0s 156us/step - loss: 0.1456\n",
            "Epoch 769/1000\n",
            "12/12 [==============================] - 0s 138us/step - loss: 0.1456\n",
            "Epoch 770/1000\n",
            "12/12 [==============================] - 0s 118us/step - loss: 0.1456\n",
            "Epoch 771/1000\n",
            "12/12 [==============================] - 0s 110us/step - loss: 0.1456\n",
            "Epoch 772/1000\n",
            "12/12 [==============================] - 0s 103us/step - loss: 0.1456\n",
            "Epoch 773/1000\n",
            "12/12 [==============================] - 0s 184us/step - loss: 0.1456\n",
            "Epoch 774/1000\n",
            "12/12 [==============================] - 0s 126us/step - loss: 0.1456\n",
            "Epoch 775/1000\n",
            "12/12 [==============================] - 0s 158us/step - loss: 0.1456\n",
            "Epoch 776/1000\n",
            "12/12 [==============================] - 0s 151us/step - loss: 0.1456\n",
            "Epoch 777/1000\n",
            "12/12 [==============================] - 0s 159us/step - loss: 0.1456\n",
            "Epoch 778/1000\n",
            "12/12 [==============================] - 0s 167us/step - loss: 0.1456\n",
            "Epoch 779/1000\n",
            "12/12 [==============================] - 0s 140us/step - loss: 0.1455\n",
            "Epoch 780/1000\n",
            "12/12 [==============================] - 0s 171us/step - loss: 0.1455\n",
            "Epoch 781/1000\n",
            "12/12 [==============================] - 0s 161us/step - loss: 0.1455\n",
            "Epoch 782/1000\n",
            "12/12 [==============================] - 0s 145us/step - loss: 0.1455\n",
            "Epoch 783/1000\n",
            "12/12 [==============================] - 0s 154us/step - loss: 0.1455\n",
            "Epoch 784/1000\n",
            "12/12 [==============================] - 0s 164us/step - loss: 0.1455\n",
            "Epoch 785/1000\n",
            "12/12 [==============================] - 0s 135us/step - loss: 0.1455\n",
            "Epoch 786/1000\n",
            "12/12 [==============================] - 0s 182us/step - loss: 0.1455\n",
            "Epoch 787/1000\n",
            "12/12 [==============================] - 0s 153us/step - loss: 0.1455\n",
            "Epoch 788/1000\n",
            "12/12 [==============================] - 0s 140us/step - loss: 0.1455\n",
            "Epoch 789/1000\n",
            "12/12 [==============================] - 0s 158us/step - loss: 0.1455\n",
            "Epoch 790/1000\n",
            "12/12 [==============================] - 0s 152us/step - loss: 0.1455\n",
            "Epoch 791/1000\n",
            "12/12 [==============================] - 0s 203us/step - loss: 0.1454\n",
            "Epoch 792/1000\n",
            "12/12 [==============================] - 0s 177us/step - loss: 0.1454\n",
            "Epoch 793/1000\n",
            "12/12 [==============================] - 0s 165us/step - loss: 0.1454\n",
            "Epoch 794/1000\n",
            "12/12 [==============================] - 0s 152us/step - loss: 0.1454\n",
            "Epoch 795/1000\n",
            "12/12 [==============================] - 0s 150us/step - loss: 0.1454\n",
            "Epoch 796/1000\n",
            "12/12 [==============================] - 0s 141us/step - loss: 0.1454\n",
            "Epoch 797/1000\n",
            "12/12 [==============================] - 0s 155us/step - loss: 0.1454\n",
            "Epoch 798/1000\n",
            "12/12 [==============================] - 0s 134us/step - loss: 0.1454\n",
            "Epoch 799/1000\n",
            "12/12 [==============================] - 0s 143us/step - loss: 0.1454\n",
            "Epoch 800/1000\n",
            "12/12 [==============================] - 0s 177us/step - loss: 0.1454\n",
            "Epoch 801/1000\n",
            "12/12 [==============================] - 0s 162us/step - loss: 0.1454\n",
            "Epoch 802/1000\n",
            "12/12 [==============================] - 0s 154us/step - loss: 0.1454\n",
            "Epoch 803/1000\n",
            "12/12 [==============================] - 0s 121us/step - loss: 0.1454\n",
            "Epoch 804/1000\n",
            "12/12 [==============================] - 0s 132us/step - loss: 0.1454\n",
            "Epoch 805/1000\n",
            "12/12 [==============================] - 0s 136us/step - loss: 0.1454\n",
            "Epoch 806/1000\n",
            "12/12 [==============================] - 0s 133us/step - loss: 0.1454\n",
            "Epoch 807/1000\n",
            "12/12 [==============================] - 0s 159us/step - loss: 0.1454\n",
            "Epoch 808/1000\n",
            "12/12 [==============================] - 0s 160us/step - loss: 0.1453\n",
            "Epoch 809/1000\n",
            "12/12 [==============================] - 0s 151us/step - loss: 0.1453\n",
            "Epoch 810/1000\n",
            "12/12 [==============================] - 0s 166us/step - loss: 0.1453\n",
            "Epoch 811/1000\n",
            "12/12 [==============================] - 0s 184us/step - loss: 0.1453\n",
            "Epoch 812/1000\n",
            "12/12 [==============================] - 0s 170us/step - loss: 0.1453\n",
            "Epoch 813/1000\n",
            "12/12 [==============================] - 0s 125us/step - loss: 0.1453\n",
            "Epoch 814/1000\n",
            "12/12 [==============================] - 0s 143us/step - loss: 0.1453\n",
            "Epoch 815/1000\n",
            "12/12 [==============================] - 0s 136us/step - loss: 0.1453\n",
            "Epoch 816/1000\n",
            "12/12 [==============================] - 0s 163us/step - loss: 0.1453\n",
            "Epoch 817/1000\n",
            "12/12 [==============================] - 0s 147us/step - loss: 0.1453\n",
            "Epoch 818/1000\n",
            "12/12 [==============================] - 0s 134us/step - loss: 0.1453\n",
            "Epoch 819/1000\n",
            "12/12 [==============================] - 0s 182us/step - loss: 0.1453\n",
            "Epoch 820/1000\n",
            "12/12 [==============================] - 0s 204us/step - loss: 0.1453\n",
            "Epoch 821/1000\n",
            "12/12 [==============================] - 0s 168us/step - loss: 0.1453\n",
            "Epoch 822/1000\n",
            "12/12 [==============================] - 0s 136us/step - loss: 0.1453\n",
            "Epoch 823/1000\n",
            "12/12 [==============================] - 0s 133us/step - loss: 0.1453\n",
            "Epoch 824/1000\n",
            "12/12 [==============================] - 0s 127us/step - loss: 0.1453\n",
            "Epoch 825/1000\n",
            "12/12 [==============================] - 0s 175us/step - loss: 0.1453\n",
            "Epoch 826/1000\n",
            "12/12 [==============================] - 0s 178us/step - loss: 0.1453\n",
            "Epoch 827/1000\n",
            "12/12 [==============================] - 0s 168us/step - loss: 0.1453\n",
            "Epoch 828/1000\n",
            "12/12 [==============================] - 0s 161us/step - loss: 0.1453\n",
            "Epoch 829/1000\n",
            "12/12 [==============================] - 0s 154us/step - loss: 0.1453\n",
            "Epoch 830/1000\n",
            "12/12 [==============================] - 0s 163us/step - loss: 0.1453\n",
            "Epoch 831/1000\n",
            "12/12 [==============================] - 0s 167us/step - loss: 0.1453\n",
            "Epoch 832/1000\n",
            "12/12 [==============================] - 0s 162us/step - loss: 0.1453\n",
            "Epoch 833/1000\n",
            "12/12 [==============================] - 0s 190us/step - loss: 0.1452\n",
            "Epoch 834/1000\n",
            "12/12 [==============================] - 0s 137us/step - loss: 0.1452\n",
            "Epoch 835/1000\n",
            "12/12 [==============================] - 0s 133us/step - loss: 0.1452\n",
            "Epoch 836/1000\n",
            "12/12 [==============================] - 0s 132us/step - loss: 0.1452\n",
            "Epoch 837/1000\n",
            "12/12 [==============================] - 0s 114us/step - loss: 0.1452\n",
            "Epoch 838/1000\n",
            "12/12 [==============================] - 0s 499us/step - loss: 0.1452\n",
            "Epoch 839/1000\n",
            "12/12 [==============================] - 0s 162us/step - loss: 0.1452\n",
            "Epoch 840/1000\n",
            "12/12 [==============================] - 0s 116us/step - loss: 0.1452\n",
            "Epoch 841/1000\n",
            "12/12 [==============================] - 0s 147us/step - loss: 0.1452\n",
            "Epoch 842/1000\n",
            "12/12 [==============================] - 0s 149us/step - loss: 0.1452\n",
            "Epoch 843/1000\n",
            "12/12 [==============================] - 0s 140us/step - loss: 0.1452\n",
            "Epoch 844/1000\n",
            "12/12 [==============================] - 0s 164us/step - loss: 0.1452\n",
            "Epoch 845/1000\n",
            "12/12 [==============================] - 0s 138us/step - loss: 0.1452\n",
            "Epoch 846/1000\n",
            "12/12 [==============================] - 0s 126us/step - loss: 0.1452\n",
            "Epoch 847/1000\n",
            "12/12 [==============================] - 0s 178us/step - loss: 0.1452\n",
            "Epoch 848/1000\n",
            "12/12 [==============================] - 0s 175us/step - loss: 0.1452\n",
            "Epoch 849/1000\n",
            "12/12 [==============================] - 0s 176us/step - loss: 0.1452\n",
            "Epoch 850/1000\n",
            "12/12 [==============================] - 0s 148us/step - loss: 0.1452\n",
            "Epoch 851/1000\n",
            "12/12 [==============================] - 0s 148us/step - loss: 0.1452\n",
            "Epoch 852/1000\n",
            "12/12 [==============================] - 0s 136us/step - loss: 0.1452\n",
            "Epoch 853/1000\n",
            "12/12 [==============================] - 0s 129us/step - loss: 0.1452\n",
            "Epoch 854/1000\n",
            "12/12 [==============================] - 0s 165us/step - loss: 0.1452\n",
            "Epoch 855/1000\n",
            "12/12 [==============================] - 0s 138us/step - loss: 0.1452\n",
            "Epoch 856/1000\n",
            "12/12 [==============================] - 0s 136us/step - loss: 0.1452\n",
            "Epoch 857/1000\n",
            "12/12 [==============================] - 0s 179us/step - loss: 0.1452\n",
            "Epoch 858/1000\n",
            "12/12 [==============================] - 0s 192us/step - loss: 0.1452\n",
            "Epoch 859/1000\n",
            "12/12 [==============================] - 0s 161us/step - loss: 0.1452\n",
            "Epoch 860/1000\n",
            "12/12 [==============================] - 0s 141us/step - loss: 0.1452\n",
            "Epoch 861/1000\n",
            "12/12 [==============================] - 0s 152us/step - loss: 0.1452\n",
            "Epoch 862/1000\n",
            "12/12 [==============================] - 0s 154us/step - loss: 0.1452\n",
            "Epoch 863/1000\n",
            "12/12 [==============================] - 0s 135us/step - loss: 0.1452\n",
            "Epoch 864/1000\n",
            "12/12 [==============================] - 0s 143us/step - loss: 0.1452\n",
            "Epoch 865/1000\n",
            "12/12 [==============================] - 0s 130us/step - loss: 0.1452\n",
            "Epoch 866/1000\n",
            "12/12 [==============================] - 0s 158us/step - loss: 0.1452\n",
            "Epoch 867/1000\n",
            "12/12 [==============================] - 0s 162us/step - loss: 0.1452\n",
            "Epoch 868/1000\n",
            "12/12 [==============================] - 0s 157us/step - loss: 0.1452\n",
            "Epoch 869/1000\n",
            "12/12 [==============================] - 0s 140us/step - loss: 0.1452\n",
            "Epoch 870/1000\n",
            "12/12 [==============================] - 0s 133us/step - loss: 0.1452\n",
            "Epoch 871/1000\n",
            "12/12 [==============================] - 0s 143us/step - loss: 0.1452\n",
            "Epoch 872/1000\n",
            "12/12 [==============================] - 0s 142us/step - loss: 0.1452\n",
            "Epoch 873/1000\n",
            "12/12 [==============================] - 0s 133us/step - loss: 0.1452\n",
            "Epoch 874/1000\n",
            "12/12 [==============================] - 0s 203us/step - loss: 0.1452\n",
            "Epoch 875/1000\n",
            "12/12 [==============================] - 0s 163us/step - loss: 0.1452\n",
            "Epoch 876/1000\n",
            "12/12 [==============================] - 0s 157us/step - loss: 0.1452\n",
            "Epoch 877/1000\n",
            "12/12 [==============================] - 0s 173us/step - loss: 0.1452\n",
            "Epoch 878/1000\n",
            "12/12 [==============================] - 0s 152us/step - loss: 0.1452\n",
            "Epoch 879/1000\n",
            "12/12 [==============================] - 0s 134us/step - loss: 0.1452\n",
            "Epoch 880/1000\n",
            "12/12 [==============================] - 0s 143us/step - loss: 0.1452\n",
            "Epoch 881/1000\n",
            "12/12 [==============================] - 0s 129us/step - loss: 0.1452\n",
            "Epoch 882/1000\n",
            "12/12 [==============================] - 0s 166us/step - loss: 0.1452\n",
            "Epoch 883/1000\n",
            "12/12 [==============================] - 0s 173us/step - loss: 0.1451\n",
            "Epoch 884/1000\n",
            "12/12 [==============================] - 0s 147us/step - loss: 0.1451\n",
            "Epoch 885/1000\n",
            "12/12 [==============================] - 0s 198us/step - loss: 0.1451\n",
            "Epoch 886/1000\n",
            "12/12 [==============================] - 0s 159us/step - loss: 0.1451\n",
            "Epoch 887/1000\n",
            "12/12 [==============================] - 0s 197us/step - loss: 0.1451\n",
            "Epoch 888/1000\n",
            "12/12 [==============================] - 0s 135us/step - loss: 0.1451\n",
            "Epoch 889/1000\n",
            "12/12 [==============================] - 0s 195us/step - loss: 0.1451\n",
            "Epoch 890/1000\n",
            "12/12 [==============================] - 0s 169us/step - loss: 0.1451\n",
            "Epoch 891/1000\n",
            "12/12 [==============================] - 0s 141us/step - loss: 0.1451\n",
            "Epoch 892/1000\n",
            "12/12 [==============================] - 0s 147us/step - loss: 0.1451\n",
            "Epoch 893/1000\n",
            "12/12 [==============================] - 0s 134us/step - loss: 0.1451\n",
            "Epoch 894/1000\n",
            "12/12 [==============================] - 0s 140us/step - loss: 0.1451\n",
            "Epoch 895/1000\n",
            "12/12 [==============================] - 0s 135us/step - loss: 0.1451\n",
            "Epoch 896/1000\n",
            "12/12 [==============================] - 0s 134us/step - loss: 0.1451\n",
            "Epoch 897/1000\n",
            "12/12 [==============================] - 0s 151us/step - loss: 0.1451\n",
            "Epoch 898/1000\n",
            "12/12 [==============================] - 0s 146us/step - loss: 0.1451\n",
            "Epoch 899/1000\n",
            "12/12 [==============================] - 0s 194us/step - loss: 0.1451\n",
            "Epoch 900/1000\n",
            "12/12 [==============================] - 0s 181us/step - loss: 0.1451\n",
            "Epoch 901/1000\n",
            "12/12 [==============================] - 0s 138us/step - loss: 0.1451\n",
            "Epoch 902/1000\n",
            "12/12 [==============================] - 0s 137us/step - loss: 0.1451\n",
            "Epoch 903/1000\n",
            "12/12 [==============================] - 0s 142us/step - loss: 0.1451\n",
            "Epoch 904/1000\n",
            "12/12 [==============================] - 0s 136us/step - loss: 0.1451\n",
            "Epoch 905/1000\n",
            "12/12 [==============================] - 0s 149us/step - loss: 0.1451\n",
            "Epoch 906/1000\n",
            "12/12 [==============================] - 0s 149us/step - loss: 0.1451\n",
            "Epoch 907/1000\n",
            "12/12 [==============================] - 0s 139us/step - loss: 0.1451\n",
            "Epoch 908/1000\n",
            "12/12 [==============================] - 0s 132us/step - loss: 0.1451\n",
            "Epoch 909/1000\n",
            "12/12 [==============================] - 0s 163us/step - loss: 0.1451\n",
            "Epoch 910/1000\n",
            "12/12 [==============================] - 0s 157us/step - loss: 0.1451\n",
            "Epoch 911/1000\n",
            "12/12 [==============================] - 0s 138us/step - loss: 0.1451\n",
            "Epoch 912/1000\n",
            "12/12 [==============================] - 0s 164us/step - loss: 0.1451\n",
            "Epoch 913/1000\n",
            "12/12 [==============================] - 0s 173us/step - loss: 0.1451\n",
            "Epoch 914/1000\n",
            "12/12 [==============================] - 0s 159us/step - loss: 0.1451\n",
            "Epoch 915/1000\n",
            "12/12 [==============================] - 0s 157us/step - loss: 0.1451\n",
            "Epoch 916/1000\n",
            "12/12 [==============================] - 0s 144us/step - loss: 0.1451\n",
            "Epoch 917/1000\n",
            "12/12 [==============================] - 0s 156us/step - loss: 0.1451\n",
            "Epoch 918/1000\n",
            "12/12 [==============================] - 0s 150us/step - loss: 0.1451\n",
            "Epoch 919/1000\n",
            "12/12 [==============================] - 0s 174us/step - loss: 0.1451\n",
            "Epoch 920/1000\n",
            "12/12 [==============================] - 0s 179us/step - loss: 0.1451\n",
            "Epoch 921/1000\n",
            "12/12 [==============================] - 0s 156us/step - loss: 0.1451\n",
            "Epoch 922/1000\n",
            "12/12 [==============================] - 0s 118us/step - loss: 0.1451\n",
            "Epoch 923/1000\n",
            "12/12 [==============================] - 0s 150us/step - loss: 0.1451\n",
            "Epoch 924/1000\n",
            "12/12 [==============================] - 0s 165us/step - loss: 0.1451\n",
            "Epoch 925/1000\n",
            "12/12 [==============================] - 0s 131us/step - loss: 0.1451\n",
            "Epoch 926/1000\n",
            "12/12 [==============================] - 0s 161us/step - loss: 0.1451\n",
            "Epoch 927/1000\n",
            "12/12 [==============================] - 0s 142us/step - loss: 0.1451\n",
            "Epoch 928/1000\n",
            "12/12 [==============================] - 0s 171us/step - loss: 0.1451\n",
            "Epoch 929/1000\n",
            "12/12 [==============================] - 0s 172us/step - loss: 0.1451\n",
            "Epoch 930/1000\n",
            "12/12 [==============================] - 0s 124us/step - loss: 0.1451\n",
            "Epoch 931/1000\n",
            "12/12 [==============================] - 0s 172us/step - loss: 0.1451\n",
            "Epoch 932/1000\n",
            "12/12 [==============================] - 0s 136us/step - loss: 0.1451\n",
            "Epoch 933/1000\n",
            "12/12 [==============================] - 0s 173us/step - loss: 0.1451\n",
            "Epoch 934/1000\n",
            "12/12 [==============================] - 0s 136us/step - loss: 0.1451\n",
            "Epoch 935/1000\n",
            "12/12 [==============================] - 0s 145us/step - loss: 0.1451\n",
            "Epoch 936/1000\n",
            "12/12 [==============================] - 0s 124us/step - loss: 0.1451\n",
            "Epoch 937/1000\n",
            "12/12 [==============================] - 0s 171us/step - loss: 0.1451\n",
            "Epoch 938/1000\n",
            "12/12 [==============================] - 0s 153us/step - loss: 0.1451\n",
            "Epoch 939/1000\n",
            "12/12 [==============================] - 0s 155us/step - loss: 0.1451\n",
            "Epoch 940/1000\n",
            "12/12 [==============================] - 0s 159us/step - loss: 0.1451\n",
            "Epoch 941/1000\n",
            "12/12 [==============================] - 0s 131us/step - loss: 0.1451\n",
            "Epoch 942/1000\n",
            "12/12 [==============================] - 0s 156us/step - loss: 0.1451\n",
            "Epoch 943/1000\n",
            "12/12 [==============================] - 0s 142us/step - loss: 0.1451\n",
            "Epoch 944/1000\n",
            "12/12 [==============================] - 0s 160us/step - loss: 0.1451\n",
            "Epoch 945/1000\n",
            "12/12 [==============================] - 0s 119us/step - loss: 0.1451\n",
            "Epoch 946/1000\n",
            "12/12 [==============================] - 0s 169us/step - loss: 0.1451\n",
            "Epoch 947/1000\n",
            "12/12 [==============================] - 0s 191us/step - loss: 0.1451\n",
            "Epoch 948/1000\n",
            "12/12 [==============================] - 0s 149us/step - loss: 0.1451\n",
            "Epoch 949/1000\n",
            "12/12 [==============================] - 0s 166us/step - loss: 0.1451\n",
            "Epoch 950/1000\n",
            "12/12 [==============================] - 0s 160us/step - loss: 0.1451\n",
            "Epoch 951/1000\n",
            "12/12 [==============================] - 0s 145us/step - loss: 0.1451\n",
            "Epoch 952/1000\n",
            "12/12 [==============================] - 0s 153us/step - loss: 0.1451\n",
            "Epoch 953/1000\n",
            "12/12 [==============================] - 0s 179us/step - loss: 0.1451\n",
            "Epoch 954/1000\n",
            "12/12 [==============================] - 0s 143us/step - loss: 0.1451\n",
            "Epoch 955/1000\n",
            "12/12 [==============================] - 0s 137us/step - loss: 0.1451\n",
            "Epoch 956/1000\n",
            "12/12 [==============================] - 0s 155us/step - loss: 0.1451\n",
            "Epoch 957/1000\n",
            "12/12 [==============================] - 0s 124us/step - loss: 0.1451\n",
            "Epoch 958/1000\n",
            "12/12 [==============================] - 0s 125us/step - loss: 0.1451\n",
            "Epoch 959/1000\n",
            "12/12 [==============================] - 0s 146us/step - loss: 0.1451\n",
            "Epoch 960/1000\n",
            "12/12 [==============================] - 0s 195us/step - loss: 0.1451\n",
            "Epoch 961/1000\n",
            "12/12 [==============================] - 0s 172us/step - loss: 0.1451\n",
            "Epoch 962/1000\n",
            "12/12 [==============================] - 0s 164us/step - loss: 0.1451\n",
            "Epoch 963/1000\n",
            "12/12 [==============================] - 0s 138us/step - loss: 0.1451\n",
            "Epoch 964/1000\n",
            "12/12 [==============================] - 0s 130us/step - loss: 0.1451\n",
            "Epoch 965/1000\n",
            "12/12 [==============================] - 0s 134us/step - loss: 0.1451\n",
            "Epoch 966/1000\n",
            "12/12 [==============================] - 0s 151us/step - loss: 0.1451\n",
            "Epoch 967/1000\n",
            "12/12 [==============================] - 0s 130us/step - loss: 0.1451\n",
            "Epoch 968/1000\n",
            "12/12 [==============================] - 0s 158us/step - loss: 0.1451\n",
            "Epoch 969/1000\n",
            "12/12 [==============================] - 0s 142us/step - loss: 0.1451\n",
            "Epoch 970/1000\n",
            "12/12 [==============================] - 0s 167us/step - loss: 0.1451\n",
            "Epoch 971/1000\n",
            "12/12 [==============================] - 0s 168us/step - loss: 0.1451\n",
            "Epoch 972/1000\n",
            "12/12 [==============================] - 0s 150us/step - loss: 0.1451\n",
            "Epoch 973/1000\n",
            "12/12 [==============================] - 0s 155us/step - loss: 0.1451\n",
            "Epoch 974/1000\n",
            "12/12 [==============================] - 0s 139us/step - loss: 0.1451\n",
            "Epoch 975/1000\n",
            "12/12 [==============================] - 0s 143us/step - loss: 0.1451\n",
            "Epoch 976/1000\n",
            "12/12 [==============================] - 0s 129us/step - loss: 0.1451\n",
            "Epoch 977/1000\n",
            "12/12 [==============================] - 0s 132us/step - loss: 0.1451\n",
            "Epoch 978/1000\n",
            "12/12 [==============================] - 0s 132us/step - loss: 0.1451\n",
            "Epoch 979/1000\n",
            "12/12 [==============================] - 0s 131us/step - loss: 0.1451\n",
            "Epoch 980/1000\n",
            "12/12 [==============================] - 0s 140us/step - loss: 0.1451\n",
            "Epoch 981/1000\n",
            "12/12 [==============================] - 0s 150us/step - loss: 0.1451\n",
            "Epoch 982/1000\n",
            "12/12 [==============================] - 0s 147us/step - loss: 0.1451\n",
            "Epoch 983/1000\n",
            "12/12 [==============================] - 0s 130us/step - loss: 0.1451\n",
            "Epoch 984/1000\n",
            "12/12 [==============================] - 0s 137us/step - loss: 0.1451\n",
            "Epoch 985/1000\n",
            "12/12 [==============================] - 0s 173us/step - loss: 0.1451\n",
            "Epoch 986/1000\n",
            "12/12 [==============================] - 0s 164us/step - loss: 0.1451\n",
            "Epoch 987/1000\n",
            "12/12 [==============================] - 0s 136us/step - loss: 0.1451\n",
            "Epoch 988/1000\n",
            "12/12 [==============================] - 0s 111us/step - loss: 0.1451\n",
            "Epoch 989/1000\n",
            "12/12 [==============================] - 0s 162us/step - loss: 0.1451\n",
            "Epoch 990/1000\n",
            "12/12 [==============================] - 0s 128us/step - loss: 0.1451\n",
            "Epoch 991/1000\n",
            "12/12 [==============================] - 0s 128us/step - loss: 0.1451\n",
            "Epoch 992/1000\n",
            "12/12 [==============================] - 0s 159us/step - loss: 0.1451\n",
            "Epoch 993/1000\n",
            "12/12 [==============================] - 0s 139us/step - loss: 0.1451\n",
            "Epoch 994/1000\n",
            "12/12 [==============================] - 0s 140us/step - loss: 0.1451\n",
            "Epoch 995/1000\n",
            "12/12 [==============================] - 0s 150us/step - loss: 0.1451\n",
            "Epoch 996/1000\n",
            "12/12 [==============================] - 0s 129us/step - loss: 0.1451\n",
            "Epoch 997/1000\n",
            "12/12 [==============================] - 0s 129us/step - loss: 0.1451\n",
            "Epoch 998/1000\n",
            "12/12 [==============================] - 0s 107us/step - loss: 0.1451\n",
            "Epoch 999/1000\n",
            "12/12 [==============================] - 0s 116us/step - loss: 0.1451\n",
            "Epoch 1000/1000\n",
            "12/12 [==============================] - 0s 110us/step - loss: 0.1451\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ffb10b031d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5Mn4L6wWdik",
        "colab_type": "text"
      },
      "source": [
        "### Visualizing weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyERNOW2z-0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx_to_neigh = {0: 'Tenderloin', 1: 'Soma', 2: 'Civic', 3: 'F. District'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzHKugAgzt-l",
        "colab_type": "code",
        "outputId": "8bc4a0b1-a4c9-46be-de67-af609a1d6fd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "model.layers[0].get_weights()[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.39984998, -0.31723857],\n",
              "       [-0.36673504,  0.33516884],\n",
              "       [ 0.64898163, -0.6414774 ],\n",
              "       [-0.59376293,  0.6124335 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "are6DJQv8wAT",
        "colab_type": "code",
        "outputId": "f8f77212-1a26-4e2d-e9b8-ac29647e9747",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "e_weights = model.layers[0].get_weights()[0]; e_weights"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.39984998, -0.31723857],\n",
              "       [-0.36673504,  0.33516884],\n",
              "       [ 0.64898163, -0.6414774 ],\n",
              "       [-0.59376293,  0.6124335 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aw6eBJK19FCh",
        "colab_type": "code",
        "outputId": "40103c90-2bf5-4978-97c8-49a1441e30f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(e_weights[:, 0], e_weights[:, 1])\n",
        "for i, coord in enumerate(e_weights):\n",
        "    plt.text(coord[0], coord[1]+0., idx_to_neigh[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niCgMREQEhYGIiKAwEBERFAYiIgL8f79LJAmioNtiAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skAmf-lK-_nG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}